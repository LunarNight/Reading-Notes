#9.虚拟内存
 进程是与其他进程共享CPU和主存资源的.然而,共享主存会形成一些特殊的挑战.随着对CPU需求的增长,进程以某种合理的平滑方式慢下来.但是如果太多的进程需要太多的内存,那么它们中的一些根本无法运行.当一个程序没有空间可用时.内存还很容易被破坏.如果某个进程不小心写了另一个进程使用的内存,它就可能以某种完全和程序逻辑无关的令人迷惑的方式失败.  
 为了更加有效地管理内存并且少出错,现代系统提供了一种对主存的抽象概念,叫做**虚拟内存(VM)**.虚拟内存是硬件异常,硬件地址翻译,主存,磁盘文件和内核软件的完美交互,它为每个进程提供了一个大的,一直的和私有的地址空间.通过一个清晰的机制,虚拟内存提供了三个重要的能力: 1)它将主存看成是一个存储在磁盘上的地址空间的告诉缓存,在主存中只保存活动区域,并根据需要在磁盘和主存之间来回传送数据,通过这种方式高效地使用了主存. 2)它为每个进程提供了一致的地址空间,从而简化了内存管理. 3)它保存了每个进程的地址空间不被其他进程破坏.  
 虚拟内存是计算机系统最重要的概念之一.它成功的一个主要原因就是因为它是沉默地,自动地工作的,不需要应用程序员的任何干涉.  
 需要理解它的原因:  
 + **虚拟内存是核心的.**虚拟内存遍及计算机系统的所有层面,在硬件异常,汇编器,链接器,加载器,共享对象,文件和进程的设计中扮演着重要角色.理解虚拟内存可以更好地理解系统通常是如何工作的.  
 + **虚拟内存是强大的.**虚拟内存基于应用程序强大的能力,可以创建和销毁内存片(chunk),将内存片映射到磁盘文件的某个部分,以及与其他进程共享内存.比如,通过读写内存位置或者修改一个磁盘文件的内容,可以加载一个文件的内容到内存,而不需要进行任何显式地复制.理解虚拟内存将帮助你利用它的强大功能在应用程序中添加动力.  
 + **虚拟内存是危险的**.每次应用程序引用一个变量,间接引用一个指针,或者调用一个诸如malloc这样的动态分配程序时,它就会和虚拟内存发生交互.如果虚拟内存使用不当,应用将遇到复杂危险的与内存有关的错误.刘丽茹,一个带有错误指针的程序可以立即崩溃于"段错误"或者"保护错误",它可能在崩溃之前还默默地运行了几个小时,或者是最令人惊慌地,运行完成却产生不正确的结果.  
  
前一部分描述虚拟内存是如何工作的.后一部分描述的是应用程序如何使用和管理虚拟内存.
##9.1 物理和虚拟寻址
 计算机系统的主存被组织成一个由M个连接的字节大小的单元组成的数组.每字节都有一个唯一的物理地址.CPU访问内存的最自然的方式就是使用物理地址.我们把这种方式称为物理寻址.  
 现代处理器使用的是一种称为虚拟寻址的寻址形式,CPU通过生成一个**虚拟地址(Virtual Address,VA)**来访问主存,这个虚拟地址在被送到内存之前先转换成适当的物理地址.将一个虚拟地址转换为物理地址的任务叫做**地址翻译**.  
##9.2 地址空间
 **地址空间(address space)**是一个非负整数地址的有序集合.  
 如果地址空间中的正数是连续的,那么我们说它是一个线性地址空间(linear address space).为了简化讨论,总是假设使用的是线性地址空间.  
 一个地址空间的大小是由表示最大地址所需要的位数来描述的.例如,一个包含N=2<sup>n</sup>个地址的虚拟地址空间就叫做一个n位地址空间.现代操作系统通常支持32位或者64位虚拟地址空间.  
 一个系统还有一个物理地址空间,对应于系统中物理内存的M个字节.  
 地址空间的概念很重要,它清楚地区分了数据对象(字节)和它们的属性(地址).**允许每个数据对象有多个独立的地址,每个地址都选自一个不同的地址空间.这就是虚拟内存的基本思想**.主存中的每字节都有一个选自虚拟地址空间的虚拟地址和一个选自物理地址空间的物理地址.  
##9.3 虚拟内存作为缓存的工具
 **虚拟内存**被组织为一个由**存放在磁盘上**的N个连续的字节大小的单元组成的**数组**.每字节都有一个唯一的虚拟地址,作为到数组的索引.磁盘上数组的内容被缓存在主存中.和存储器层次结构中其他缓存一样,磁盘(较低层)上的数据被分割成块,这些块作为磁盘和主存(较高层)之间的传输单元.VM系统通过将虚拟内存分割为称为**虚拟页(Vittual Page,VP)**的大小固定的块来处理这个问题.每个虚拟页的大小为P=2<sup>p</sup>字节.类似地,物理内存被分割为物理页,大小也为P字节(物理页也被称为页帧).  
 在任意时刻,虚拟页面的集合都分为三个不相交的子集:  
 + 未分配的:VM系统还未分配(或者创建)的页.未分配的块没有任何数据和它们相关联,因此也就不占用任何磁盘空间.  
 + 缓存的: 当前已缓存在物理内存中的已分配页.  
 + 未缓存的:未缓存在物理内存中的已分配页.  
  
###9.3.1 DRAM缓存的组织结构
 将使用术语SRAM缓存来表示位于CPU和主存之间的L1,L2和L3高速缓存,并且用术语DRAM缓存来表示虚拟内存系统的缓存,它在主存中缓存虚拟页.  
 在存储层次结构中,DRAM缓存的位置对它的组织结构有很大的影响.DRAM比SRAM要慢大约10倍,磁盘要比DRAM慢大约100000多倍.因此,DRAM缓存中的不命中比起SRA没缓存中的不命中要昂贵得多,这是因为DRA没缓存不命中要由磁盘来服务,而SRAM缓存不命中通常是由基于DRAM的主存来服务的.而且,从磁盘的一个扇区读取第一个字节的时间开销比起读这个扇区中连续的字节要慢100000倍,归根到底,DRAM缓存的组织结构完全是由巨大的不命中开销驱动的.  
 因为大的不命中出发和访问第一个字节的开销,徐你也往往很大,通常是4KB~2MB.由于大的不命中出发,DRAM缓存是全相联的,即任何徐你也都可以放置在任何的物理页中.不命中时的替换策略也和你重要,因为替换错了徐你也的出发也非常之高.因此,与硬件对SRAM缓存相比,操作系统对DRAM缓存使用了更复杂精密的替换算法.最后,因为对磁盘的访问时间很长,DRAM缓存总是使用写会,而不是直写.  
###9.3.2 页表
 同任何缓存一样,虚拟内存系统必须有某种方法来判定一个徐你也是否缓存在DRAM中的某个地方.如果是,系统还必须确定这个虚拟页存放在哪个物理页中.如果不命中,系统必须判断这个虚拟页存放在磁盘的哪个位置,在物理内存中选择一个牺牲页,并将虚拟页从磁盘复制到DRAM中,替换这个牺牲页.  
 这些功能式由软硬件联合提供的,包括操作系统软件,MMU(内存管理单元)中的地址翻译硬件和一个存放在物理内存中叫做**页表(page table)**的数据结构,页表将虚拟页映射到物理页.每次地址翻译硬件将一个虚拟地址转换为物理地址时,都会读取页表.操作系统负责维护页表的内容,以及在磁盘与DRAM之间来回传送页.  
 页表就是一个**页表条目(Page Table Entry,PTE)**的数组.虚拟地址空间中的每个页在页表中一个固定偏移量处都有一个PTE.为了我们的目的,假设每个PTE是由一个有效位和一个n位地址字段组成的.有效位表明了该虚拟页当前是否被缓存在DRAM中.如果设置了有效位,那么地址字段就表示DRAM中相应的物理页的起始位置,这个物理页中缓存了该虚拟页.如果没有设置有效位,那么一个空地址表示这个虚拟页还未被分配.否则,这个地址就指向该虚拟页在磁盘上的起始位置.  
 因为DRAM缓存是全相联的,所以任意物理页都可以包含任意虚拟页.  
###9.3.3 页命中
 地址翻译硬件将虚拟地址作为一个索引来定位 PET 2,并从内存中读取它.因为设置了有效位,那么地址翻译硬件就知道 VP2 是缓存在内存中的了.所以它使用PTE中的物理内存地址(该地址指向 PP1 中缓存页的起始位置),构造出这个字的物理地址.  
###9.3.4 缺页
 在虚拟内存的习惯说法中,DRAM缓存不命中称为**缺页**.即CPU引用了 VP3 中的一个字, VP3并未被缓存在DRAM中.  
 地址翻译硬件从内存中读取 PTE3,从有效位推断出VP3未被缓存,并且触发一个缺页异常.缺页异常调用内核中的缺页异常处理程序,该程序会选择一个牺牲也,在此例就是存放在 PP3中的 VP4.如果VP4已经被修改了,那么内核就会将它复制到磁盘.无论哪种情况,内核都会修改VP4的页表条目,反映出VP4不再缓存在主存中这一事实.  
 接下来,内核从磁盘复制VP3到内存中的PP3,更新PTE3,随后返回.当异常处理程序返回时,它会重新启动导致缺页的指令,该指令会把导致缺页的虚拟地址重发送到地址翻译硬件.但是现在,VP3已结缓存在主存了,那么页命中也能由地址翻译硬件正常处理了.  
***
 虚拟内存系统使用了和SRAM缓存不同的术语,即使它们的许多概念是相似的.在虚拟内存的习惯说法中,块被称为页.在磁盘和内存之间传送页的活动叫做交换(swapping)或者页面调度(paging).页从磁盘换入(或者页面调入)DRAM和从DRAM换出(或者页面调出)磁盘.一直等待,直到最后时刻,也就是当有不命中发生时,才还如页面的这种策略称为按需页面调度.  
 尽管在整个运行过程中程序引用的不同页面的总数可能超出物理内存总的大小,但是局部性原则保证了在任意时刻,程序将趋向于在一个较小的活动页面集合上工作,这个集合叫做工作集或者常驻集合.在初始开销,也就是将工作集页面调度到内存中之后,接下来对这个工作集的引用将导致命中,而不会产生额外的磁盘流量.  
 只要程序有好的时间局部性,虚拟内存系统就能工作的很好,但是,当然不是所有的程序都能展现良好的时间局部性.**如果工作集的大小超出了物理内存的大小,那么程序将产生一种不幸的状态,叫做抖动,这时页面将不断地换进换出.**  
##9.4 虚拟内存作为内存管理的工具
 在上一节中,看到虚拟内存是如何提供一种机制,利用DRAM缓存来自通常更大的虚拟地址空间的页面.  
 到目前为止,我们都假设有一个单独的页表,将一个虚拟地址空间映射到物理地址空间.实际上,操作系统为每个进程提供了一个独立的页表,因而也就是一个独立的虚拟地址空间.**多个虚拟页面可以映射到同一个共享物理页面上**.  
***
 按需页面调度和独立的虚拟地址空间的结合,对系统中内存的使用和管理造成了深远的影响.VM简化了链接和加载,代码和数据共享,以及应用程序的内存分配.  
 + 简化链接.独立的地址空间允许每个进程的内存映像使用相同的基本格式,而不管代码和数据实际存放在物理内存的何处.一个给定的Linux系统上的每个进程都使用类似的内存格式.对于64位地址空间,代码段总是从虚拟地址0x400000开始.数据段跟在代码段之后,中间有一段符合要求的对齐空白.栈占据用户进程地址空间最高的部分,并向下生长.这样的一致性极大地简化了链接器的设计和实现,允许链接器生成完全连接的可执行文件,这些可执行文件是独立于物理内存中代码和数据的最终位置的.  
 + 简化加载.虚拟内存还使得容易向内存中加载可执行文件和共享对象文件.要把目标文件中.text和.data节加载到一个新创建的进程中,Linux加载器位代码和数据段分配虚拟页,把它们标记为无效的(即未被缓存的),将页表条目指向目标文件中适当的位置.有趣的是,加载器从不从磁盘到内存实际复制任何数据.在每个页初次被引用时,要么是CPU取指令时引用的,要么是一条正在执行的指令引用一个内存位置时引用的,虚拟内存系统会按照需要自动地跳入数据页.将一组连续的虚拟页映射到任意一个文件中的任意位置的表示法称作**内存映射**.Linux提供一个称为nmap的系统调用,允许应用程序自己做内存映射.  
 + 简化共享.独立地址空间为操作系统提供了一个管理用户进程和操作系统自身之间共享的一致机制.一般而言,每个进程都有自己私有的代码,数据,堆以及栈区域,是不和其他进程共享的.在这种情况下,操作系统创建页表,将相应的虚拟页映射到不连续的物理页面.  
 然而一些情况中,还是需要进程来共享代码和数据的.例如,每个进程必须调用相同的操作系统内核代码,而每个C程序员都会调用C标准库中的程序,比如printf.操作系统通过将不同进程中适当的虚拟页面映射到相同的物理页面,从而安排多个进程共享这部分代码的一个副本,而不是在每个进程中都包括单独的内核和C标准库的副本.  
 + 简化内存分配.虚拟内存为向用户进程提供一个简单的分配额外内存的机制.当一个运行在用户进程中的程序要求额外的堆空间时(调用malloc),操作系统分配一个适当数字(例如k)个连续的虚拟内存页面,并且将它们映射到物理内存中任意位置的k个位置的物理页面.由于页表工作的方式,操作系统没有必要分配k个连续的物理内存页面.页面可以随机地分散在物理内存中.  
  
##9.5 虚拟内存作为内存保护的工具
 任何现代计算机系统必须为操作系统提供手段来控制对内存系统的访问.不应该允许一个用户进程修改它的只读代码段.而且也不应该允许它读或修改任何内核中的代码和数据结构.不应该允许它读或者写其他进程的私有内存,不允许它修改任何与其他进程共享的虚拟页面,除非所有的共享者都显式地允许它这么做(通过调用明确的进程间通信系统调用)  
 提供独立的地址空间使得区分不同进程的私有内存变得容易.但是,地址翻译机制可以以一种自然的方式扩展到提供更好的访问控制.因为每次CPU生成一个地址时,地址翻译硬件都会读一个PTE,所以通过**在PTE上添加一些额外的许可位来控制对一个虚拟页面内容的访问十分简单.**  
##9.6 地址翻译
 CPU中的一个控制寄存器,**页面基址寄存器(Page Table Base Register, PTBR)**指向当前页表.n位的虚拟地址包括两个部分:一个p位的虚拟页面偏移(Virtual Page Offset, VPO)和一个(n-p)位的虚拟页号(Vitrtual Page Number,VPN).MMU利用VPN来选择适当的PTE.例如,VPN 0 选择 PTE 0.将页表条目中物理页号(PPN)和虚拟地址中的VPO串联起来,就得到相应的物理地址.因为物理和虚拟页面都是P字节的.所以物理页面偏移 PPO 和 VPO 是相同的.  
 CPU硬件执行的步骤(省略了一个图):  
 + 第一步.处理器生成一个虚拟地址,并把它传送给MMU.  
 + 第二步.MMU生成PTE,并从高速缓存/主存请求得到它.  
 + 第三步.高速缓存/主存向MMU返回PTE.  
 + 第四步.MMU构造物理地址,并把它传送给高速缓存/主存.  
 + 第五步.高速缓存/主存返回所请求的数组字给处理器.  
  
页面命中完全是由硬件来处理的,与此不同的是,处理缺页要求硬件和操作系统内核协作完成.  
 + 第1~3步和上述相同.  
 + 第四步. PTE中的有效位是0,所以MMU出发了一次异常,传递CPU中的控制到操作系统内核中的缺页异常处理程序.
 + 第五步. 却也处理程序确定出物理内存中的牺牲页,如果这个页面已经被修改,则把它换出到磁盘.
 + 第六步. 却也处理程序页面调入新的页面,并更新内存中的PTE.  
 + 第七步. 却也处理程序返回给原来的进程,在此之星导致缺页的指令.CPU将引起缺页的虚拟地址重新发送给MMU.因为虚拟页面现在缓存在物理内存中,所以就会命中.
  
###9.6.1 结合高速缓存和虚拟内存
 大多数系统是选择物理寻址的.使用物理寻址,多个进程同时在高速缓存中有存储块和共享来自相同虚拟页面的块称为很简单的事情.而且,高速缓存无需处理保护问题,因为访问权限的检查是地址翻译过程的一部分.主要的思路是**地址翻译发生在高速缓存之前**,注意:页表条目可以缓存,就像其他的数据字一样.  
  
###9.6.2 利用TLB加速地址翻译  
 每次CPU产生一个虚拟地址,MMU就必须查阅一个PTE,将虚拟地址翻译为物理地址.最糟糕的情况下,会要求从内存多取一次数据,代价是几十到几百个周期.**如果PTE碰巧缓存在L1中**,那么开销就下降到1或2个周期.许多系统都试图消除这样的开销,它们在MMU中包括了一个关于PTE的小的缓存,称为**翻译后备缓冲器(Translation Lookaside Buffer,TLB).**  
 TLB是一个小的,虚拟寻址的缓存,其中每一行都保存着一个由单个PTE组成的块.用于**组选择**和**行匹配**的**索引和标记字段**是从虚拟地址中的**虚拟页号**提取出来的.如果TLB 有 T = 2<SUB>t</SUB>个组,那么TLB索引 是由 VPN的 t 个最低位组成的,而 TLB标记是由VPN中剩余的位组成的.  
 **(虚拟地址看二进制的位表示 = 虚拟页(VPN)位 + 虚拟页码偏移量(VPO)位, 而TLB索引和 TLB偏移 是把 VPN的 n位进行拆分, 进行相应的表示,从而在PLB中查找)**  
 所有的地址翻译步骤都是在芯片上的MMU中执行的,因此非常快.  
 + 1. CPU产生了一个虚拟地址.
 + 2. MMU从TLB中取出对应的PTE
 + 3. MMU将这个虚拟地址翻译成一个物理地址,并将它发送到高速缓存/主存.
 + 4. 高速缓存/主存将锁清秋的数据字返回给CPU.
当TLB不命中时,MMU必须从L1缓存中取出相应的PTE,新取出的PTE存放在TLB中,可能会覆盖一个已经存在的条目.  
###9.6.3 多级页表
 到目前为止,一直假设系统只用一个单独的页表来进行地质翻译.如果有一个32位的地址空间,4KB的页面和一个4字节的PTE.即使应用所引用的只是虚拟地址空间中很小的一部分,也总是需要一个4MB的页面驻留在内存中.对于地址空间位64位系统来说,问题将变得更复杂.  
 **用来压缩页表的常用方法是使用层次结构的页表.**一级页表中的每个PTE负责映射虚拟地址空间中一个4MB的片(chunk),这里每一片都是由1024个连续的页面组成的.比如,PTE0映射第一片.假设地址空间是4GB,1024个PTE已经足够覆盖整个空间了.  
 如果片i中的每个页面都未被分配,那么一级PTEi就为空.如果在片i中至少有一个页是分配了的,那么一级PTEi就指向一个二级页表的基址.  
 **(多级页表 也是缓存思想,在一级页表中,其中的一条数据代表 二级页表中的许多个数据, 这样只需要把一级的加载到主存中,就可以减少主存空间的使用,需要二级页表的时候再把二级页表创建,页面调入或调出.减少了主存的压力,只有最经常使用的二级页表才需要缓存在主存中)**  
 k级页表层次结构的地址翻译.虚拟地址被划分为k个VPN和1个VPO.每个VPN i 都是一个到第 i 级页表的索引. 第j级页表中的每个PTE,都指向j+1级的某个页表的基址.  
###9.6.4 综合:端到端的地址翻译
 + TLB.TLB是利用VPN的位进行虚拟寻址的.因为TLB有4个组,所以VPN的低2位就作为组索引(TLBI).VPN中剩下的高6位作为标记(TLBT),用来区别可能映射到同一个TLB组的不同的VPN.
 + 页表.这个页表是一个单级设计,一共有 256 个页表条目(PTE).为了方便,用索引它的VPN来标志每个PTE.但是**这些VPN并不是页表的一部分**,也不存储在内存中.每个无效PTE的PPN都用一个破折号来表示,以加强一个概念:无论刚好这里存储的是什么位值,都是没有任何意义的.  
 + 高速缓存.直接映射的缓存是通过物理地址中的字段来寻址的.因为每个块是4字节,所以物理地址的低2位都作为块偏移(co).因为有16组,所以接下来的4位用来表示组索引(CI).剩下的6位作为标记(CT).


TLB中缓存部分PTE.MMU根据一个PTE进行翻译,从高速缓存或内存中取出物理地址的数据.  
通过**虚拟地址**来查找TLB标记和索引(根据VPN),从**TLB**中进行查找,如果找不到,就从主存中抽取出相应PTE.**找到**的话,得到**PPN(物理页号)和VPO**结合,**得到物理地址**,从物理地址中**抽出CO,CI,CT**,在**缓存中进行查找**,看是否命中.**(主要的操作流程请看黑体加粗)**  
##9.7 案例研究:Intel Core I7/Lunux 内存系统
###9.7.1 Core i7地址翻译
 当MMU翻译每一个虚拟地址时,它还会更新另外两个内核缺页处理程序会用到的位.每次访问一个页时,MMU会设置A位,称为**引用位(reference bit)**.内核可以用这个引用位来实现它的页替换算法.每次对一个页进行了写之后,MMU都会设置D位,又称**修改位**或脏位(dirty bit).修改位告诉内核在复制替换页之前是否必须写回牺牲页.内核可以通过调用一条特殊的内核模式指令来清楚引用位或修改位.  
###9.7.2 Linux虚拟内存系统
 这一节,可以让你大致了解一个实际的操作系统是如何组织虚拟内存,以及如何处理缺页的.  
 Linux为每个进程维护了一个单独的虚拟地址空间,包括它那些熟悉的代码,数据,堆,共享库以及栈段.  
 内核虚拟内存包含内核中的代码和数据结构.内核虚拟内存的某些区域被映射到所有进程共享的物理页面.例如,每个进程共享内核的代码和全局数据结构.Linux也将一组连续的虚拟页面(大小等于系统中DRAM的总量)映射到相应的一组连续的物理页面.这就为内核提供了一种遍历的方法来访问物理内存中任何特定的位置,例如,它需要访问页表,或在一些设备上执行内存映射的I/O操作,而这些设备被映射到特定的物理内存位置时.内核虚拟内存的其他区域包含每个进程都不相同的数据.比如说,页表,内核在进程的上下文中执行代码时使用的栈,以及记录虚拟地址空间当前组织的各种数据结构.  
  
 **1.Linux虚拟内存区域**  
 Linux将虚拟内存组织成一些区域(也叫段)的集合.一个区域就是已经存在着的(已分配的)虚拟内存的连续片,这些页是以某种方式相关联的.例如,代码段,数据段,堆,共享库段,以及用户栈都是不同的区域.每个存在的虚拟页面都保存在某个区域中,而不属于某个区域的虚拟页是不存在的,并且不能被进程引用.区域的概念很重要,因为它允许虚拟地址空间有间隙.内核不用记录那些不存在的虚拟页,而这一的虚拟页页不占用内存,磁盘或者内核本身中的任何额外资源.  
 **2.Linux缺页异常处理**  
 假如MMU在试图翻译某个虚拟地址A时,触发了一个缺页.这个异常导致控制转移到内核的缺页处理程序.会执行以下步骤.  
 1)虚拟地址A是**合法**的吗?A在某个区域结构定义的区域内吗?缺页处理程序搜索区域结构的链表.如果这个指令是**不合法**的,缺页处理程序就会触发一个**段错误**.  
 2)试图进行的内存访问是否**合法**?进程是否有读,写或者执行这个区域内页面的**权限**?**缺页**是否是由一条试图对这个代码段里制度页面进行写操作的**存储指令造成**的?这个缺页是不是因为一个运行在用户模式中的进程试图**从内核虚拟内存中读取字**造成的?如果试图进行的访问是不合法的,那么就会触发一个保护异常,终止进程.  
 3)此刻,内核知道了这个**缺页是由于对合法的虚拟地址进行合法的操作造成的**.它是这样来处理这个缺页的:选择一个**牺牲页面**,如果牺牲页面**被修改过**,就把它**交换出去**,换入新的页面并更新页表.当缺页处理程序返回时,CPU重新启动引起缺页的指令,这条指令将再次发送A到MMU.这次,MMU就可以正常翻译A,不在产生缺页中断.  
##9.8 内存映射
 Linux通过将一个虚拟内存区域与一个磁盘上的对象关联起来,以初始化这个虚拟内存区域的内容,这个过程称为**内存映射**.虚拟内存区域可以映射到两种类型的对象的一种:  
 + Linux文件系统中的普通文件: 一个区域可以映射到一个普通磁盘文件的连续部分,例如一个可执行目标文件.文件区(section)被分成页大小的片,每一片包含一个虚拟页面的初始内容.因为按需进行页面调度,所以这些虚拟页面没有实际交换进入物理内存,直到CPU第一次引用到页面(即发射一个虚拟地址,落在地址空间这个页面的范围之内).如果区域比文件要哒,那么就用零来填充这个区域的余下部分.  
 + 匿名文件: 一个区域也可以映射到一个匿名文件,匿名文件是由内核创建的,包含的全是而禁止令.CPU第一次引用这样一个区域内的虚拟页面时,内核就在屋里内存中找到一个合适的牺牲也面,如果该页面被修改过,就将这个页面换出来,用二进制零覆盖牺牲页面并更新页表,将这个页面标记为是驻留在内存中的.注意在磁盘和内存之间并没有实际的数据传送.因为这个原因,映射到匿名文件的区域中的页面又是也叫作**请求二进制零的页**.  
无论哪种情况下,一旦一个虚拟页面被初始化了,他就在一个由内核维护的专门的交换文件之间换来换去.交换文件也叫作交换空间或者交换区域.需要意识到的很重要的一点是,**在任何时刻,交换空间都闲置着当前运行着的进程能够分配的虚拟页面的总数**  
###9.8.1 再看共享对象
 进程这一抽象能够为每个进程提供自己私有的虚拟地址空间,可以避免受其他进程的错误读写.不过,许多进程有同样的制度代码区域.例如,每个C程序都需要来自标准C库的诸如printf这样的函数.如果每个进程都在物理内存中保持这些常用代码的副本,那就是极端的浪费了.幸运的是,**内存映射**给我们提供了一种清晰的机制,用来**控制多个进程如何共享对象**.  
 一个对象可以被映射到虚拟内存的一个区域,要么作为共享对象,要么作为四有对象.如果一个进程将一个共享对象映射到它的虚拟地址空间的一个区域内,那么这个建材城对这个区域的任何写操作,对于那些也把这个共享对象映射到它们虚拟内存的其他进程而言,也是可见的.(好像快捷方式的感觉)而且这些变化也会反应在磁盘上的原始对象中.  
 另一方面,对于一个映射到是有对象的区域做的改变,对于其他今晨来说是不可见的,进程对这个区域所作的任何写操作都不会反映在磁盘上的对象中.一个映射到共享对象的虚拟内存区域叫做共享区域.类似地,也有私有区域.  
 维护共享对象的时候,物理内存只需要存放共享对象的一个副本.  
 私有对象使用一种叫做**写时复制**的技术被映射到虚拟内存中.一个是有对象开始生命周期的方式基本上与共享对象的一样,在物理内存中只保存有私有对象的一份副本.对于每个映射是有对象的进程,相同私有区域的页表条目都被标记为只读,并且**区域结构被标记为私有的写时复制**.只要没有进程试图写它的私有区域,它们就可以继续共享物理内存中对象的一个单独副本.只要有一个进程试图写私有区域内的某个页面,那么这个写操作就会触发一个保护故障.  
 当故障处理程序注意到保护异常是由于进程试图写私有的写时复制区域中的一个页面而引起的,他就会在物理内存中创建这个页面的一个新副本,更新页表条目指向这个新的副本,然后恢复这个页面的可写权限.当故障处理程序返回时,CPU重新执行这个写操作,现在 在新创建的页面上这个写操作就可以正常执行了.  
 通过延迟是有对象中的副本直到最后可能的时刻,写时复制最充分地使用了稀有的物理内存.  
###9.8.2 再看fork函数
 当fork函数被当前进程调用时,内核为新进程创建各种数据结构,并分配给它一个唯一的PID.为了给这个新进程创建虚拟内存,它创建了当前进程的mm_struct,区域结构和页表的原样副本.它将两个进程中的每个页面都标记为只读,将两个进程中的每个区域结构都标记为私有的写时复制.  
 当fork在新进程中返回时买新进程现在的虚拟内存刚好和调用fork时存在的虚拟内存相同.当两个进程中的任一个后来进行写操作时,写时复制机制就会创建新页面,因此,也就是每个进程保持了私有地址空间的抽象概念.  
###9.8.3 再看execve函数
 假设运行当前进程中的程序执行了如下的execve调用  
 execve("a.out",NULL,NULL);  
 execve函数在当前进程中加载并运行包含在可执行目标文件a.out中的程序,用a.out程序有效地替代了当前程序.加载并运行a.out需要以下几个步骤.  
 + **删除已存在的用户区域**.删除当前进程虚拟地址的用户互粉中的已存在的区域结构.  
 + **映射私有区域**.为新程序的代码,数据,bss和栈区域创建新的区域结构.所有这些新的区域都是私有的,写时复制的.代码和数据区域被映射为a.out文件中的.text和.data区.bss区域是请求二进制零的,映射到匿名文件,其大小包含在a.out中.栈和堆区域也是请求而禁止令的,初始长度为零.  
 + **映射共享区域**.如果a.out程序与共享对象(目标)链接,比如标准C库libc.so,那么这些对象都是动态链接到这个程序的,然后再映射到用户虚拟地址空间中的共享区域内.  
 + **设置程序计数器(PC)**.execve做的最后一件事情就是设置当前进程上下文中的程序计数器.使之指向代码区域的入口点.  
  
##9.9 动态内存分配
 当运行时需要额外虚拟内存时,用动态内存分配器(dynamic memory allocator)更方便.也有更好的可移植性.  
 动态内存分配器维护者一个进程的虚拟内存区域,称为堆(heap).系统之间细节不同,但是不失通用性,假设堆是一个请求二进制零的区域,它紧接在未初始化的数据区域后开始,并向上生长(更高的地址).对于每个进程,内核维护者一个变量brk,它指向堆的顶部.  
 分配器将堆视为一组不同大小的块(block)的集合来维护.每个块就是一个连续的虚拟内存片,要么是已分配的,要么是空闲的.已分配的块显式地保留为供应用程序使用.空闲块可以用来分配.空闲块保持空闲,知道它显式地被应用所分配.一个已分配的块保持已分配状态,直到它被释放,这种释放要么是应用程序显式执行的,要么是内存分配器自身隐式执行的.  
 分配器有两种基本风格.不同之处在于哪个实体来负责释放已分配的块.  
 + 显式分配器(explicit allocator).要求应用显式地释放任何已分配的块.例如,C标准库提供一种叫做malloc程序包的显式分配器.CC横须通过调用malloc函数来分配一个块,并通过调用free函数来释放一个块.  
 + 隐式分配器(implicit allocator).要求分配器检测一个已分配块合适不再被程序所使用,那么就释放这个块,隐式分配器也叫作垃圾收集器,而自动释放未使用的已分配的块的过程叫做垃圾收集.  

程序使用动态内存分配的最重要原因是经常直到程序实际运行时,才知道某些数据结构的大小.  
 malloc函数返回一个指针,指向大小为至少size字节的内存块,这个块会为可能包含在这个块内的任何数据对象类型做**对齐**.  
###9.9.3 分配器的要求和目标
 显式分配器必须在一些相当严格的约束条件下工作:  
 + 处理任意请求序列.一个应用可以有任意的分配请求和释放请求序列,只要满足约束条件:每个释放请求必须对应于一个当前已分配块,这个块是由一个以前的分配请求获得的.因此,分配器不可以假设分配和释放请求的顺序.例如,分配器不能假设所有的分配请求都有相匹配的释放请求,或者有相匹配的分配和空闲请求是嵌套的.  
 + 立即响应请求.分配器必须立即响应分配请求.因此,不允许分配器为了提高性能重新排列或者缓存请求.  
 + 只是用堆.为了使分配器是可扩展的,分配器使用的任何非标量数据结构都必须保存在堆里.  
 + 对齐块(对齐要求).分配器必须对齐块,使得它们可以保存任何类型的数据对象.  
 + 不修改已分配的块.分配器只能操作或者改变空闲块.特别是,一旦块被分配了,就不允许修改或者移动它了.因此,诸如压缩已分配块这样的技术是不允许使用的.  
在这些限制条件下,分配器编写者试图实现吞吐率最大化和内存使用率最大化,而这两个性能目标通常是相互冲突的.
 + 目标1: 最大化吞吐率.吞吐率定义为每个单位时间里完成的请求数.例如,如果一个分配器在1秒内完成500个分配请求和500个释放请求,那么它的吞吐率就是每秒1000次操作.一般而言,我们可以通过使满足分配和释放请求的平均时间最小化来使吞吐率最大化.  
 + 目标2: 最大化内存利用率.实际上,一个系统中被所有进程分配的虚拟内存的全部数量是受磁盘上交换空间的数量限制的.虚拟内存是一个有限的空间,必须高效地使用.对于可能被要求分配和释放大块内存的动态内存分配器来说也是如此.  
###9.9,4 碎片
 造成堆利用率很低的主要原因是一种称为碎片(fragmentation)的现象,当虽然有未使用的内存但不能用来满足分配请求时,就发生这种现象.有两种形式的碎片:内部碎片和外部碎片.  
 **内部碎片**是一个已分配块比有效载荷大时发生的.很多原因可能造成这个问题.例如,一个分配器的实现可能对已分配块强加一个最小的大小值,而这个大小比某个请求的有效载荷大.分配器可能增加块大小以满足对齐约束条件.比如你需要5个空间.分配了8个(为了满足对齐要求).
 内部碎片的数量只取决于以前请求的模式和分配器的实现方式.  
 **外部碎片**是当空闲内存合计起来足够满足一个分配请求,但是没有一个单独的空闲块足够大可以来处理这个请求是发生的.如果请求6个空闲的字,如果有虚拟内存中有6个空闲的字,但是6个字分在两个空闲块中,就无法请求成功.  
 外部碎片比内部碎片的量化要苦难的多,因为它不仅取决于以前请求的模式和分配器的实现方式,还取决于将来请求的模式.因为外部碎片难以量化且不可能预测,所以分配器通常采用启发式策略来试图维持少量的大孔线块,而不是维持大量的小空闲块.  
###9.9.6 隐式空闲链表
 任何实际的分配器都需要一些数据结构,允许它来区别块边界,以及区别已分配块和空闲块.大多数分配器将这些信息嵌入块本身.  
 一个块是由一个字的头部,有效载荷,以及可能的一些额外的填充组成的.头部编码了这个块的大小(包括头部和所有的填充),以及这个块是已分配的还是空闲的,如果我们强加一个双字的对齐约束条件,那么块大小就总是8的倍数,且块大小的最低3位总是令.因此,我们只需要内存大小的29个高位,释放剩余的3位来编码其他信息.在这种情况中,我们用其中的最低位来致命这个块是已分配的还是空闲的.  
 我们称这种结构为隐式空闲链表,是因为空闲块是通过头部中的大小字段隐含地链接着的,分配器可以通过遍历对中所有的块,从而间接地遍历整个空闲块的集合.  
 系统对齐要求和分配器对块格式的选择会对分配器上的最小块大小有强制的要求.没有已分配块或者空闲块可以比这个最小值还小.如果我们假设一个双字的对齐要求,那么每个块的大小都必须是双字(8字节)的倍数.  
##9.10 垃圾收集
 垃圾收集器是一种动态内存分配器,它自动释放程序不再需要的已分配块,这些块被称为垃圾.在一个支持垃圾收集的系统中,应用显式分配堆块,但是从不显示地释放它们.  
###9.10.1 垃圾收集器的基本知识
 垃圾收集器将内存视为一张有向可达图(reachability graph),该图的节点被分成一组根节点和一组堆节点.每个堆节点对应于堆中的一个已分配块.有向边p->q意味着块p中的某个位置指向块q中的某个位置.根节点对应于这样一种不在堆中的位置,它们中包含指向堆中的指针.这些位置可以是寄存器,栈里的变量,或者是虚拟内存中读写数据区域内的全局变量.  
 **当存在一条从任意根节点出发并到达p的有向路径时,我们说节点p是可达的.在任何时刻,不可达节点对应于垃圾**  
###9.10.2 Mark Sweep垃圾收集器
 Mark Sweep垃圾收集器由标记阶段和清除阶段组成,标记阶段标记处根节点的所有可达的和已分配的后继,而后面的清除阶段释放每个未被标记的已分配块.  
 C不会用任何类型信息来标记内存位置.对isPtr没有一种明显的方式判断他的输入参数p是不是一个指针.即使知道p是一个指针,也没有明显的方式来判断p是否指向一个已分配块的有效载荷中的某个位置.  
 C程序的 MS收集器必须是保守的,根本原因是C语言不会用类型信息来标记内存位置.像int或者float这样的标量可以伪装成指针.假设某个可达的已分配块在它的有效载荷中包含一个int,其值碰巧对应于某个其他已分配快b的有效载荷中的一个位置.对收集器而言,是没办法判断出这个数据实际上是int而不是指针.分配器必须保守的将块b标记为可达,尽管事实上它可能是不可达的.  
##9.11 C程序中常见的与内存有关的错误  
###9.11.1间接引用坏指针
 在进程的虚拟地址空间中有较大的洞,没有映射到任何有意义的数据.如果我们试图间接引用一个指向这些洞的指针,那么操作系统就会以段异常中止程序.而且,虚拟内存的某些区域是只读的.试图写这些区域将会以保护异常中止这个程序.  
 间接引用坏指针的一个常见示例是经典的scanf错误.  
 假设我们想要使用scanf从stdin读一个整数到一个变量.
