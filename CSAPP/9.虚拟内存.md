#9.虚拟内存
 进程是与其他进程共享CPU和主存资源的.然而,共享主存会形成一些特殊的挑战.随着对CPU需求的增长,进程以某种合理的平滑方式慢下来.但是如果太多的进程需要太多的内存,那么它们中的一些根本无法运行.当一个程序没有空间可用时.内存还很容易被破坏.如果某个进程不小心写了另一个进程使用的内存,它就可能以某种完全和程序逻辑无关的令人迷惑的方式失败.  
 为了更加有效地管理内存并且少出错,现代系统提供了一种对主存的抽象概念,叫做**虚拟内存(VM)**.虚拟内存是硬件异常,硬件地址翻译,主存,磁盘文件和内核软件的完美交互,它为每个进程提供了一个大的,一直的和私有的地址空间.通过一个清晰的机制,虚拟内存提供了三个重要的能力: 1)它将主存看成是一个存储在磁盘上的地址空间的告诉缓存,在主存中只保存活动区域,并根据需要在磁盘和主存之间来回传送数据,通过这种方式高效地使用了主存. 2)它为每个进程提供了一致的地址空间,从而简化了内存管理. 3)它保存了每个进程的地址空间不被其他进程破坏.  
 虚拟内存是计算机系统最重要的概念之一.它成功的一个主要原因就是因为它是沉默地,自动地工作的,不需要应用程序员的任何干涉.  
 需要理解它的原因:  
 + **虚拟内存是核心的.**虚拟内存遍及计算机系统的所有层面,在硬件异常,汇编器,链接器,加载器,共享对象,文件和进程的设计中扮演着重要角色.理解虚拟内存可以更好地理解系统通常是如何工作的.  
 + **虚拟内存是强大的.**虚拟内存基于应用程序强大的能力,可以创建和销毁内存片(chunk),将内存片映射到磁盘文件的某个部分,以及与其他进程共享内存.比如,通过读写内存位置或者修改一个磁盘文件的内容,可以加载一个文件的内容到内存,而不需要进行任何显式地复制.理解虚拟内存将帮助你利用它的强大功能在应用程序中添加动力.  
 + **虚拟内存是危险的**.每次应用程序引用一个变量,间接引用一个指针,或者调用一个诸如malloc这样的动态分配程序时,它就会和虚拟内存发生交互.如果虚拟内存使用不当,应用将遇到复杂危险的与内存有关的错误.刘丽茹,一个带有错误指针的程序可以立即崩溃于"段错误"或者"保护错误",它可能在崩溃之前还默默地运行了几个小时,或者是最令人惊慌地,运行完成却产生不正确的结果.  
  
前一部分描述虚拟内存是如何工作的.后一部分描述的是应用程序如何使用和管理虚拟内存.
##9.1 物理和虚拟寻址
 计算机系统的主存被组织成一个由M个连接的字节大小的单元组成的数组.每字节都有一个唯一的物理地址.CPU访问内存的最自然的方式就是使用物理地址.我们把这种方式称为物理寻址.  
 现代处理器使用的是一种称为虚拟寻址的寻址形式,CPU通过生成一个**虚拟地址(Virtual Address,VA)**来访问主存,这个虚拟地址在被送到内存之前先转换成适当的物理地址.将一个虚拟地址转换为物理地址的任务叫做**地址翻译**.  
##9.2 地址空间
 **地址空间(address space)**是一个非负整数地址的有序集合.  
 如果地址空间中的正数是连续的,那么我们说它是一个线性地址空间(linear address space).为了简化讨论,总是假设使用的是线性地址空间.  
 一个地址空间的大小是由表示最大地址所需要的位数来描述的.例如,一个包含N=2<sup>n</sup>个地址的虚拟地址空间就叫做一个n位地址空间.现代操作系统通常支持32位或者64位虚拟地址空间.  
 一个系统还有一个物理地址空间,对应于系统中物理内存的M个字节.  
 地址空间的概念很重要,它清楚地区分了数据对象(字节)和它们的属性(地址).**允许每个数据对象有多个独立的地址,每个地址都选自一个不同的地址空间.这就是虚拟内存的基本思想**.主存中的每字节都有一个选自虚拟地址空间的虚拟地址和一个选自物理地址空间的物理地址.  
##9.3 虚拟内存作为缓存的工具
 **虚拟内存**被组织为一个由**存放在磁盘上**的N个连续的字节大小的单元组成的**数组**.每字节都有一个唯一的虚拟地址,作为到数组的索引.磁盘上数组的内容被缓存在主存中.和存储器层次结构中其他缓存一样,磁盘(较低层)上的数据被分割成块,这些块作为磁盘和主存(较高层)之间的传输单元.VM系统通过将虚拟内存分割为称为**虚拟页(Vittual Page,VP)**的大小固定的块来处理这个问题.每个虚拟页的大小为P=2<sup>p</sup>字节.类似地,物理内存被分割为物理页,大小也为P字节(物理页也被称为页帧).  
 在任意时刻,虚拟页面的集合都分为三个不相交的子集:  
 + 未分配的:VM系统还未分配(或者创建)的页.未分配的块没有任何数据和它们相关联,因此也就不占用任何磁盘空间.  
 + 缓存的: 当前已缓存在物理内存中的已分配页.  
 + 未缓存的:未缓存在物理内存中的已分配页.  
  
###9.3.1 DRAM缓存的组织结构
 将使用术语SRAM缓存来表示位于CPU和主存之间的L1,L2和L3高速缓存,并且用术语DRAM缓存来表示虚拟内存系统的缓存,它在主存中缓存虚拟页.  
 在存储层次结构中,DRAM缓存的位置对它的组织结构有很大的影响.DRAM比SRAM要慢大约10倍,磁盘要比DRAM慢大约100000多倍.因此,DRAM缓存中的不命中比起SRA没缓存中的不命中要昂贵得多,这是因为DRA没缓存不命中要由磁盘来服务,而SRAM缓存不命中通常是由基于DRAM的主存来服务的.而且,从磁盘的一个扇区读取第一个字节的时间开销比起读这个扇区中连续的字节要慢100000倍,归根到底,DRAM缓存的组织结构完全是由巨大的不命中开销驱动的.  
 因为大的不命中出发和访问第一个字节的开销,徐你也往往很大,通常是4KB~2MB.由于大的不命中出发,DRAM缓存是全相联的,即任何徐你也都可以放置在任何的物理页中.不命中时的替换策略也和你重要,因为替换错了徐你也的出发也非常之高.因此,与硬件对SRAM缓存相比,操作系统对DRAM缓存使用了更复杂精密的替换算法.最后,因为对磁盘的访问时间很长,DRAM缓存总是使用写会,而不是直写.  
###9.3.2 页表
 同任何缓存一样,虚拟内存系统必须有某种方法来判定一个徐你也是否缓存在DRAM中的某个地方.如果是,系统还必须确定这个虚拟页存放在哪个物理页中.如果不命中,系统必须判断这个虚拟页存放在磁盘的哪个位置,在物理内存中选择一个牺牲页,并将虚拟页从磁盘复制到DRAM中,替换这个牺牲页.  
 这些功能式由软硬件联合提供的,包括操作系统软件,MMU(内存管理单元)中的地址翻译硬件和一个存放在物理内存中叫做**页表(page table)**的数据结构,页表将虚拟页映射到物理页.每次地址翻译硬件将一个虚拟地址转换为物理地址时,都会读取页表.操作系统负责维护页表的内容,以及在磁盘与DRAM之间来回传送页.  
 页表就是一个**页表条目(Page Table Entry,PTE)**的数组.虚拟地址空间中的每个页在页表中一个固定偏移量处都有一个PTE.为了我们的目的,假设每个PTE是由一个有效位和一个n位地址字段组成的.有效位表明了该虚拟页当前是否被缓存在DRAM中.如果设置了有效位,那么地址字段就表示DRAM中相应的物理页的起始位置,这个物理页中缓存了该虚拟页.如果没有设置有效位,那么一个空地址表示这个虚拟页还未被分配.否则,这个地址就指向该虚拟页在磁盘上的起始位置.  
 因为DRAM缓存是全相联的,所以任意物理页都可以包含任意虚拟页.  
###9.3.3 页命中
 地址翻译硬件将虚拟地址作为一个索引来定位 PET 2,并从内存中读取它.因为设置了有效位,那么地址翻译硬件就知道 VP2 是缓存在内存中的了.所以它使用PTE中的物理内存地址(该地址指向 PP1 中缓存页的起始位置),构造出这个字的物理地址.  
###9.3.4 缺页
 在虚拟内存的习惯说法中,DRAM缓存不命中称为**缺页**.即CPU引用了 VP3 中的一个字, VP3并未被缓存在DRAM中.  
 地址翻译硬件从内存中读取 PTE3,从有效位推断出VP3未被缓存,并且触发一个缺页异常.缺页异常调用内核中的缺页异常处理程序,该程序会选择一个牺牲也,在此例就是存放在 PP3中的 VP4.如果VP4已经被修改了,那么内核就会将它复制到磁盘.无论哪种情况,内核都会修改VP4的页表条目,反映出VP4不再缓存在主存中这一事实.  
 接下来,内核从磁盘复制VP3到内存中的PP3,更新PTE3,随后返回.当异常处理程序返回时,它会重新启动导致缺页的指令,该指令会把导致缺页的虚拟地址重发送到地址翻译硬件.但是现在,VP3已结缓存在主存了,那么页命中也能由地址翻译硬件正常处理了.  
***
 虚拟内存系统使用了和SRAM缓存不同的术语,即使它们的许多概念是相似的.在虚拟内存的习惯说法中,块被称为页.在磁盘和内存之间传送页的活动叫做交换(swapping)或者页面调度(paging).页从磁盘换入(或者页面调入)DRAM和从DRAM换出(或者页面调出)磁盘.一直等待,直到最后时刻,也就是当有不命中发生时,才还如页面的这种策略称为按需页面调度.  
 尽管在整个运行过程中程序引用的不同页面的总数可能超出物理内存总的大小,但是局部性原则保证了在任意时刻,程序将趋向于在一个较小的活动页面集合上工作,这个集合叫做工作集或者常驻集合.在初始开销,也就是将工作集页面调度到内存中之后,接下来对这个工作集的引用将导致命中,而不会产生额外的磁盘流量.  
 只要程序有好的时间局部性,虚拟内存系统就能工作的很好,但是,当然不是所有的程序都能展现良好的时间局部性.**如果工作集的大小超出了物理内存的大小,那么程序将产生一种不幸的状态,叫做抖动,这时页面将不断地换进换出.**  
##9.4 虚拟内存作为内存管理的工具
 在上一节中,看到虚拟内存是如何提供一种机制,利用DRAM缓存来自通常更大的虚拟地址空间的页面.  
 到目前为止,我们都假设有一个单独的页表,将一个虚拟地址空间映射到物理地址空间.实际上,操作系统为每个进程提供了一个独立的页表,因而也就是一个独立的虚拟地址空间.**多个虚拟页面可以映射到同一个共享物理页面上**.  
***
 按需页面调度和独立的虚拟地址空间的结合,对系统中内存的使用和管理造成了深远的影响.VM简化了链接和加载,代码和数据共享,以及应用程序的内存分配.  
 + 简化链接.独立的地址空间允许每个进程的内存映像使用相同的基本格式,而不管代码和数据实际存放在物理内存的何处.一个给定的Linux系统上的每个进程都使用类似的内存格式.对于64位地址空间,代码段总是从虚拟地址0x400000开始.数据段跟在代码段之后,中间有一段符合要求的对齐空白.栈占据用户进程地址空间最高的部分,并向下生长.这样的一致性极大地简化了链接器的设计和实现,允许链接器生成完全连接的可执行文件,这些可执行文件是独立于物理内存中代码和数据的最终位置的.  
 + 简化加载.虚拟内存还使得容易向内存中加载可执行文件和共享对象文件.要把目标文件中.text和.data节加载到一个新创建的进程中,Linux加载器位代码和数据段分配虚拟页,把它们标记为无效的(即未被缓存的),将页表条目指向目标文件中适当的位置.有趣的是,加载器从不从磁盘到内存实际复制任何数据.在每个页初次被引用时,要么是CPU取指令时引用的,要么是一条正在执行的指令引用一个内存位置时引用的,虚拟内存系统会按照需要自动地跳入数据页.将一组连续的虚拟页映射到任意一个文件中的任意位置的表示法称作**内存映射**.Linux提供一个称为nmap的系统调用,允许应用程序自己做内存映射.  
 + 简化共享.独立地址空间为操作系统提供了一个管理用户进程和操作系统自身之间共享的一致机制.一般而言,每个进程都有自己私有的代码,数据,堆以及栈区域,是不和其他进程共享的.在这种情况下,操作系统创建页表,将相应的虚拟页映射到不连续的物理页面.  
 然而一些情况中,还是需要进程来共享代码和数据的.例如,每个进程必须调用相同的操作系统内核代码,而每个C程序员都会调用C标准库中的程序,比如printf.操作系统通过将不同进程中适当的虚拟页面映射到相同的物理页面,从而安排多个进程共享这部分代码的一个副本,而不是在每个进程中都包括单独的内核和C标准库的副本.  
 + 简化内存分配.虚拟内存为向用户进程提供一个简单的分配额外内存的机制.当一个运行在用户进程中的程序要求额外的堆空间时(调用malloc),操作系统分配一个适当数字(例如k)个连续的虚拟内存页面,并且将它们映射到物理内存中任意位置的k个位置的物理页面.由于页表工作的方式,操作系统没有必要分配k个连续的物理内存页面.页面可以随机地分散在物理内存中.  
  
##9.5 虚拟内存作为内存保护的工具
 任何现代计算机系统必须为操作系统提供手段来控制对内存系统的访问.不应该允许一个用户进程修改它的只读代码段.而且也不应该允许它读或修改任何内核中的代码和数据结构.不应该允许它读或者写其他进程的私有内存,不允许它修改任何与其他进程共享的虚拟页面,除非所有的共享者都显式地允许它这么做(通过调用明确的进程间通信系统调用)  
 提供独立的地址空间使得区分不同进程的私有内存变得容易.但是,地址翻译机制可以以一种自然的方式扩展到提供更好的访问控制.因为每次CPU生成一个地址时,地址翻译硬件都会读一个PTE,所以通过**在PTE上添加一些额外的许可位来控制对一个虚拟页面内容的访问十分简单.**  
##9.6 地址翻译
 CPU中的一个控制寄存器,**页面基址寄存器(Page Table Base Register, PTBR)**指向当前页表.n位的虚拟地址包括两个部分:一个p位的虚拟页面偏移(Virtual Page Offset, VPO)和一个(n-p)位的虚拟页号(Vitrtual Page Number,VPN).MMU利用VPN来选择适当的PTE.例如,VPN 0 选择 PTE 0.将页表条目中物理页号(PPN)和虚拟地址中的VPO串联起来,就得到相应的物理地址.因为物理和虚拟页面都是P字节的.所以物理页面偏移 PPO 和 VPO 是相同的.  
 CPU硬件执行的步骤(省略了一个图):  
 + 第一步.处理器生成一个虚拟地址,并把它传送给MMU.  
 + 第二步.MMU生成PTE,并从高速缓存/主存请求得到它.  
 + 第三步.高速缓存/主存向MMU返回PTE.  
 + 第四步.MMU构造物理地址,并把它传送给高速缓存/主存.  
 + 第五步.高速缓存/主存返回所请求的数组字给处理器.  
  
页面命中完全是由硬件来处理的,与此不同的是,处理缺页要求硬件和操作系统内核协作完成.  
 + 第1~3步和上述相同.  
 + 第四步. PTE中的有效位是0,所以MMU出发了一次异常,传递CPU中的控制到操作系统内核中的缺页异常处理程序.
 + 第五步. 却也处理程序确定出物理内存中的牺牲页,如果这个页面已经被修改,则把它换出到磁盘.
 + 第六步. 却也处理程序页面调入新的页面,并更新内存中的PTE.  
 + 第七步. 却也处理程序返回给原来的进程,在此之星导致缺页的指令.CPU将引起缺页的虚拟地址重新发送给MMU.因为虚拟页面现在缓存在物理内存中,所以就会命中.
  
###9.6.1 结合高速缓存和虚拟内存
 大多数系统是选择物理寻址的.使用物理寻址,多个进程同时在高速缓存中有存储块和共享来自相同虚拟页面的块称为很简单的事情.而且,高速缓存无需处理保护问题,因为访问权限的检查是地址翻译过程的一部分.主要的思路是**地址翻译发生在高速缓存之前**,注意:页表条目可以缓存,就像其他的数据字一样.  
 
