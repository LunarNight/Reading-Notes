#存储器层次结构  
 存储器系统(memory system)是一个具有不同容量,成本和访问时间的存储设备的层次结构.CPU寄存器保存着最常用的数据.靠近CPU的小的,快速的**高速缓存存储器(cache memory)**作为一部分存储在相对慢速的主存储器(main memory)中数据和指令的缓冲区域.主存缓存存储在容量较大的,慢速磁盘上的数据,这些磁盘常常又作为存储在通过网络连接的其他机器的磁盘或磁带上的数据的缓冲区域.  
 计算机系统中一个基本而持久的思想:理解系统是如何将数据在存储器层次结构中上上下下移动的,就可以编写自己的应用程序,使得它们的数据项存储在层次结构中较高的地方,在那里CPU能更快地访问到它们.  
 这个思想围绕着计算机程序的一个称为**局部性(locality)**的基本属性.具有良好局部性的程序倾向于一次又一次地**访问相同的数据项集合(时间局部性)**,或是倾向于**访问临近的数据项集合(空间局部性)**.具有良好局部性的程序比局部性差的程序更多地倾向于从存储器成此结果中较高层次处访问数据项,因此运行地更快.  
##6.1 存储技术
###6.1.1随机访问存储器
 随机访问存储器(Random-Access Memory,RAM)分为两类:静态的和动态的.静态RAM(SRAM)比动态RAM(DRAM)更快,更贵.SRAM用来作为高速缓存存储器,既可以在CPU芯片上,也可以在片下.DRAM用来作为主存图形系统的帧缓冲区.  
 **1. 静态RAM**  
 SRAM将每个位存储在一个双稳态的存储单元里.每个单元是用一个六晶体管电路来实现的.这个电路有这样一个熟悉,可以无限期地保持在两个不同的电压配置()configuration)或状态(state)之一.其他任何状态都是不稳定的.从不稳定状态开始,电路会迅速地转移到两个稳定状态中的一个.这样一个单元类似于一个**钟摆**,分为左稳态,不稳定状态(在中间),右稳态(倒向右边).原则上,钟摆能在垂直的位置无期限地保持平衡,但是这个状态是亚稳态(metastable),嘴细微的扰动也能使他倒下,而且一旦倒下就永远不会再回复到垂直的位置.  
 由于SRAM存储器单元的双稳态特性,只要有电,它就会永远地保持它的值.即使有干扰,在干扰消除时,电路就会恢复到稳定值.  
 **2. 动态RAM**  
 DRAM存储器单元对干扰非常敏感,当电容的电压扰乱之后,就永远不会恢复了.暴露在光纤瞎会导致电容电压发生改变,数码照相机和摄像机中的传感器本质上就是DRAM阵列.  
 很多原因会导致漏电,使得DRAM单元在10~100毫秒时间内失去电荷.幸运的是,计算机运行的时钟周期是以纳秒来衡量的,所以相对而言这个保持时间是比较长的.内存系统必须周期性地通过独处,然后重写来刷新内存每一位.有些系统也使用纠错码,其中计算机的字会被多编码几个位(例如64位的字可能用72位来编码),这样一来,电路可以发现并纠正一个字节中任何单个的错误位.  
 **3. 传统的DRAM**  
 DRAM芯片中的单元(位)被分成d个超单元,每个超单元都由w个DRAM单元组成.一个d x w 的 DRAM总共存储了dw位信息.超单元被组织成一个r行c列的长方形阵列,这里rc=d.每个超单元有形如(i,j)的地址,i表示行,j表示列.  
 每个DRAM芯片被连接到某个称为**内存控制器**的电路,这个电路可以一次传送w位到每个DRAM芯片或一次从每个DRAM芯片传出w位.为了读出超单元(i,j)的内容,内存控制器将行地址i发送到DRAM,然后是列地址j.DRAM把超单元(i,j)的内容发挥给控制器作为相应.行地址i称为RAS(Row Access Strobe,行访问选通脉冲)请求.列地址j称为CAS请求,RAS和CAS请求共享相同的DRAM地址引脚.  
 如果要独处超单元(2,1),内存控制器发送行地址2,DRAM的相应是将行2的整个内容都复制到一个内部行缓冲区,接下来,内存控制器发送列地址1,DRAM的相应是从行缓冲区复制出超单元(2,1)中的8位,并把它们发送到内存控制器.  
 **4. 内存模块**  
 DRAM芯片封装在**内存模块(memory module)**中,内存模块的基本思想:用8个64Mbit的 8M x 8的DRAM芯片,总共存储64MB,这8个芯片编号0~7.每个超单元存储主存的一个字节,而用相应超单元地址为(i,j)的8个超单元来表示主存中字节地址A处的64位字.DRAM0存储第一个(低位)字节,DRAM1存储下一个字节,以此类推.  
 要取出内存地址A处的一个字,内存控制器将A转换成一个超单元地址(i,j),并将它发送到内存模块,然后内存模块再将i和j广播到每个DRAM.作为相应,每个DRAM输出它的(i,j)超单元的8位内容.模块中的电路手机这些输出,并把它们合并成一个64位字,再返回给内存控制器.  
 通过将多个内存模块连接到内存控制器,能够聚合成主存.在这种情况下,当控制器收到一个地址A时,控制器选择包含A的模块k,将A转换成它的(i,j)的形式,并将(i,j)发送到模块k.  
 **5. 增强的DRAM**  
 快页模式DRAM(Fast Page Mode DRAM).传统的DRAM将超单元的一整行复制到它的内部行缓冲区中,使用一个,然后丢弃剩余的.FPM DRAM允许对同意后连续地访问可以直接从行缓冲区得到服务,从而改进了这一点.例如要从一个传统的DRAM的行i中读4个超单元,内存控制器必须发送4个RAS/CAS请求,及时是行地址i在每个情况中都是一样的.要从一个FPM DRAM的同一行中读取超单元,内存控制器发送第一个RAS/CAS请求,后面跟三个CAS请求.初始的RAS/CAS请求将行i复制到行缓冲区,并返回CAS寻址的那个超单元.接下里三个超单元直接从行缓冲区获得,因此返回得比初始的超单元更快.  
 扩展数据输出DRAM(Extended Data Out DRAM,EDO DRAM).FPM DRAM的一个增强的形式,允许各个CAS信号在时间上靠的更紧密一点.  
 同步DRAM(Synchronous DRAM,SDRAM).就它们与内存控制器通信使用一组显式的控制信号来说,常规的,FPM和EDO DRAM都是异步的.SDRAM用于驱动内存控制器相同的外部时钟信号的上升沿来替代许多这样的控制信号,最终效果就是SDRAM能够比异步的存储器更快地输出它的超单元的内容.  
 **6.非易失性存储器**  
 如果断电,DRAM和SRAM会丢失它们的信息,它们是易失的(volatile).另一方面,非易失性存储器(nonvolatile memory)即使是在观点后,仍然保存着它们的信息.现在有很多种非易失性存储器.由于历史原因,虽然ROM中有的类型即可以读也可以写,但是它们整体上都被称为只读存储器(Read-Only Memory,ROM),ROM是以它们能够被重编程(写)的次数和对它们进行重编程所用的机制来区分的.  
 PROM(Programmable ROM,可编程ROM)只能被编程一次.PROM的每个存储器单元有一种熔丝(fuse),只能用高电流熔断一次.  
 可擦写可编程ROM(Erasable Programmable ROM, EPROM).电子可擦除PROM(Electrically Erasable PROM,EEPROM)类似于EPROM.  
 **闪存**(falsh memory)是一类非易失性存储器,基于EEPROM,已经成为一种重要的存储技术.一种新型的基于闪存的磁盘驱动器,称为固态硬盘(Solid State Disk,SSD),它能提供相对于传统旋转磁盘的一种更快速,更强健和更低能耗的选择.  
 存储在ROM设备中的程序通常被称为**固件(firmware)**.当一个计算机系统通电以后,会运行存储在ROM中的固件.  
 **7.访问主存**  
 数据流通过称为总线(bus)的共享电子电路在处理器和DRAM主存之间来来回回.每次CPU和主存之间的数据传送都是通过一系列步骤来完成的,这些步骤称为总线事务(bus transaction).读事务(read transaction)从主存传送数据到CPU.写事务(write transaction)从CPU传送数据到主存.  
 总线是一组并行的导线,能携带地址,数据和控制信号.取决于总线的设计,数据和地址信号可以共享同一组导线,也可以使用不同的.两个以上的设备也能共享同一总线.控制线携带的信号会同步事务,并标识出当前正在被执行的事务的类型.例如,当前关注的这个事务是到主存的吗?还是到诸如磁盘控制器这样的其他I/O设备?是读还是写?  
 计算机系统的配置,主要部件是 CPU芯片,I/O桥接器(在CPU 和 内存之间),以及组成主存的DRAM内存模块.这些组件由一堆总线连接起来,其中一条是系统总线,连接CPU和I/O桥接器,另一条是内存总线,连接I/O桥接器和主存.I/O桥接器将系统总线的电子信号翻译成内存总线的电子信号.  
***
 当CPU执行一个如下加载操作时  
 movq A,%rax  
 地址A的内容被加载到寄存器rax中,CPU芯片上称为总线接口的电路在总线上发起读事务.读事务由三个步骤组成.  
 首先,CPU将地址A放到系统总线上,I/O桥将信号传递到内存总线.  
 接下来,主存感觉到内存总线上的地址信号从内存总线度地址,从DRAM去除数据自,并将数据写到内存总线.I/O桥将内存总线信号翻译成系统总线信号,沿着系统总线传递.  
 最后,CPU感觉到系统总线上的数据,从总线上读数据,并将数据复制到寄存器rax.  
  
 当CPU执行一个相反的操作时  
 movq %rax,A  
 寄存器rax的内容被写到地址A,CPU发起写事务.  
 首先,CPU将地址放到系统总线上,内存从内存总线独处地址,等待数据到达.  
 接下来,CPU将rax中的数据字复制到系统总线.  
 最后,主存从内存总线读出数据字,并且将这些位存储到DRAM中.  
***
###6.1.2磁盘存储
 **1.磁盘构造**  
 磁盘是由盘片(platter)构成的.每个盘片由两面或者称为表面(surface),表面覆盖着磁性记录材料.盘片中央有一个可以旋转的主轴(spindle),使得盘片以固定的**旋转速率(rotational rate)**旋转,磁盘通常包含一个或多个这样的盘片,并封装在一个密封的容器内.  
 磁盘表面是由一组称为磁道(track)的同心圆组成的.每个磁道被划分为一组扇区(sector).每个扇区包含相等数量的数据位(通常是512字节),这些数据编码在扇区上的磁性材料中.扇区之间由一些间隙(gap)分隔开,这些间隙中不存储数据位.间隙存储用来标志山区的格式化位.  
 磁盘是由一个或多个叠放在一起的盘片组成的,被封装在一个密封的容器里.整个装置通常被称为**磁盘驱动器(disk drive)**,通常简称为磁盘.有时会称磁盘为旋转磁盘,区别于基于闪存的固态硬盘,SSD是没有移动部分的.  
 磁盘制造商通常用术语柱面(cylinder)来描述多个盘片驱动器的构造,这里,柱面是所有盘片表面上到主轴中心的距离相等的磁道的集合.  
 **2.磁盘容量**  
 一个磁盘上可以记录的最大位数称为它的最大容量,或者简称为容量.磁盘容量是由一下技术因素决定的:  
 记录密度(recording density):磁道一英寸的段中可以放入的位数.  
 磁道密度(track density):从盘片中心出发半径上一英寸的段内可以有的磁道数.  
 面密度(areal density):记录密度与磁道密度的乘积.  
 现代大容量磁盘使用一种称为多区记录(multiple zone recording)的技术,在这种技术中,柱面的集合被分割成不想交的子集合,称为记录区(recording zone).每个区包含一组连续的柱面.一个区中的每个柱面中的每条磁道都有相同数量的山区,这个山区的数量是由该区中最里面的磁道所能包含的山区数决定的.  
 **3.磁盘操作**  
 磁盘用读/写头来读写存储在磁性表面的位,读写头连接到一个传动臂一端.通过沿着半径轴前后移动这个传动臂,驱动器可以将读/头定位在盘面上的任何磁道上.这样的机械运动称为寻道(seek).一旦读/写头定位到了期望的磁道上,那么当磁道上的每个位通过它的下面时,读/写头可以感知到这个位的值(读该位),也可以修改这个位的值(写该位).有多个盘片的磁盘针对每个盘面都有一个独立的读/写头.读/写头垂直排列,一致行动.在任何时刻,所有的读/写头都位于同一个柱面上.  
 磁盘以山区大小的块来读写数据.对山区的访问时间(access time)有三个主要的部分:寻道时间(seek time),旋转时间(rotational latency)和传道时间(transfer time):  
 **寻道时间**:为了读取某个目标扇区的内容,传动臂首先将读/写头定位到包含目标扇区的磁道上.移动传动臂所需的时间成为寻道时间.寻道时间依赖于读/写头以前的位置和传动臂在盘面上移动的速度.  
 **旋转时间**:一旦读/写头定位到了期望的磁道,驱动器等待目标山区的第一个位旋转到读/写头瞎.这个步骤的性能依赖于当读/写头到达目标山区时盘面的位置以及磁盘的旋转速度.最坏情况下,读/写头刚刚错过了目标山区,必须等待磁盘旋转一整圈.  
 **传送时间**:当目标扇区的第一个位位于读/写头下时,驱动器就可以开始读或者写该扇区的内容了.一个扇区的传送时间依赖于旋转速度和每条磁带的扇区数目.  
  
 **4. 逻辑磁盘块**  
 为了对操作系统隐藏复杂性,现代磁盘将它们的构造呈现一个简单的视图,一个B个扇区大小的逻辑快的序列,编号为0,1,...,B-1.磁盘封装中有一个小的硬件/固件设备,称为磁盘控制器,维护者逻辑块号和实际(物理)磁盘扇区之间的映射关系.  
 当操作系统想要执行一个I/O操作时,例如读一个磁盘扇区的数据到主存,操作系统会发送一个命令道磁盘控制器,让它读某个逻辑块号.控制器上的固件执行一个快速表查找,将一个逻辑块号翻译成一个(盘面,磁道,扇区)的三元组,这个三元组唯一地标志了对应的物理山区,控制器上的硬件会解释这个三元素,将读/写头移动到适当的柱面,等待扇区移动到读/写头瞎,将读/写头感知到的位放到控制器上的一个小缓冲区中,然后把它们复制到主存中.  
 **6. 访问磁盘**  
 CPU使用一种称为内存映射I/O(memory-mapped I/O)的技术来向I/O设备发射命令.在使用内存映射I/O的系统中,地址空间中有一块地址是为与I/O设备通信保留的.每个这样的地址称为一个I/O端口.当一个设备连接到总线时,它与一个或多个端口相关联(或它被映射到一个或多个端口).  
 看一个例子,假设磁盘控制器映射到端口0xa0.随后,CPU可能通过执行三个队地址0xa0的存储指令,发起磁盘读:第一条指令是发送一个命令字,告诉磁盘发起一个读,同时还发送了其他的参数,例如当读完成时,是否中断CPU.第二条指令致命应该读的逻辑块号.第三条指令致命应该存储磁盘扇区内容的主存地址.  
 当CPU法律请求后,在磁盘执行度的时候,它通常会做些其他的工作.一个1GHz的处理器始终周期为1ns,在用来度磁盘的16ms时间里,它潜在地可能执行1600万条指令.在传输进行时,只是简单地等待,什么都不做,是一种极大的浪费.  
 在磁盘控制器收到来自CPU的杜明令之后,它将逻辑块号翻译成一个扇区地址,读该扇区的内容,然后将这些内容直接传送到主存,不需要CPU的干涉.设备可以自己执行度或者写总线事务而不需要CPU干涉的过程,称为**直接内存访问(Direct Memory Access,DMA)**.这种数据传送称为DMA传送(DMA transfer).  
 在DMA传送完成,磁盘山区的内容被安全地存储在主存中以后,磁盘控制器通过给CPU发送一个中断信号来通知CPU.  
###6.1.3 固态硬盘
 固态硬盘(Solid State Disk,SSD)是一种基于闪存的存储技术.一个SSD封装由一个或多个闪存芯片和闪存翻译层组成,闪存芯片替代传统旋转磁盘中的机械驱动器,而闪存翻译曾是一个硬件/固件设备,扮演与磁盘控制器相同的角色,对逻辑快的请求翻译成对底层物理设备的访问.  
 读SSD比写要快.随机读和写的性能差别是由底层闪存基本属性决定的.数据是以页为单位读写的.只有在一页所属的块整个被**擦除**之后,才能写这一页.不过,一旦一个块被擦除了,块中每一个页都可以不需要在进行擦除就写一次.  
 随机写很慢,有两个原因.首先,擦除块需要相对较长的时间,比访问也所需时间要高一个数量级.其次,如果写操作师徒修改一个包含已经有数据的页,那么这个块中所有带有用数据的页都必须被复制到一个新块,然后才能进行对页p的写.  
##6.2局部性  
 一个便携良好的计算机程序常常具有良好的局部性(locality).它们倾向于引用临近于其他最近引用过的数据项的数据项,或者最近引用过的数据项本身,这种倾向性,被称为局部性原理.是一个持久的概念,对硬件和软件系统的设计和性能都有着极大的影响.  
 **分为时间局部性和空间局部性**  
 程序员应该理解局部性原理,一般而言,有良好局部性的程序运行的更快.现代计算机系统的各个层次,从硬件到操作系统,再到应用程序,它们的设计都利用了局部性.在硬件层,局部性原理允许计算机设计者通过引入称为**高速缓存存储器**的小而快速的存储器来保存最近被引用的指令和数据项,从而提高对主存的访问速度.在操作系统级,局部性原理允许系统使用主存作为虚拟地址空间最近被引用块的高速缓存.类似地,磁盘块,Web浏览器.  
###6.2.1 对程序数据引用的局部性  
 顺序访问一个向量每个元素的函数,具有步长为1的引用模式(for循环中,i++),有时称这种模式为顺序引用模式.随着步长的增加,空间局部性下降.  
```
for(i = 0;i < M;i++)
  for(j = 0; j < N;j++)
    sum+=a[i][j];


for(i = 0;i < M;i++)
  for(j = 0; j < N;j++)
    sum+=a[j][1];

```
 第二个for循环,效率比较差,因为引用步长为N,没有良好的空间局部性  
###6.2.3 局部性小结
 重复引用相同变量的程序具有良好的时间局部性  
 对于具有步长为k的引用模式的程序,步长越小,空间局部性越好.  
 对于取指令来说,循环有好的时间和空间局部性.循环体越小,迭代次数越多,局部性越好.  
 
##6.3 存储器层次结构  
 存储器层次结构如下.  
 寄存器  
 L1高速缓存  
 L2高速缓存  
 L3高速缓存  
 主存  
 本地二级存储(磁盘)  
 远程二级存储(分布式文件系统,web服务器)  
###6.3.1存储器层次结构中的缓存
 高速缓存(cache)是一个小而快速的存储设备,它作为存储在更大,更慢的设备中的数据对象的缓冲区与.使用高速缓存的过程称为缓存.  
 第k层的存储器被划分成较少的块的集合,每个块的大小与k+1层的块的大小一样,任何时刻,第k层的缓存包含第k+1层块的一个子集副本.  
 数据总是以块大小为传送单元在第k层和第k+1层之间来回复制.相邻层之间块大小是固定的,但是其他的层次对之间可以有不同的块大小.  
 
 **1.缓存命中**  
 当程序需要第k+1层的某个数据对象d时,首先在第k层的一个块中查找d,如果d刚好缓存在第k层,就是缓存命中.  
 **2.缓存不命中**  
 如果第k层中没有d,就是缓存不命中.发生不命中时,第k层的缓存从第k+1层缓存中取出包含d的那个块,如果第k层满了,可能会覆盖现存的一个块.  
 **3.缓存不命中种类**  
 如果第k层是空的,一个空的缓存被称为冷缓存(cold cache),此类不命中称为强制不命中或冷不命中.冷不命中是短暂的时间,在反复访问存储器使得缓存暖身之后就不会出现.  
 如果发生不命中,就需要执行一个放置策略,确定把从第k+1层中取出的块放在哪里.  
 冲突不命中,这时缓存足够大,可是一些对象会映射到同一个缓存块,缓存会一直不命中(类似哈希表,得到的哈希值一样,周围还有很多空位置,但只会覆盖已有值)  
 当工作集的大小超狗缓存的大小时,缓存会经理容量不命中,也就是缓存太小了,不能处理这个工作集.  
###6.3.2存储器层次结构概念小结
 基于缓存的存储器层次结构行之有效,因为较慢的存储设备比较快的存储设备更便宜,还因为程序倾向于展示局部性.  
 现代操作系统中导出都使用了缓存.CPU芯片,操作系统,分布式文件系统和万维网上都使用了缓存.  
##6.4高速缓存存储器  
 由于CPU和主存之间逐渐增大的差距,系统设计者被迫在CPU寄存器文件和主存之间插入了一个小的SRAM高速缓存存储器.后来也是由于同样的原因,又插入L2,L3  
##6.4.1通用的高速缓存存储器组织结构  
 考虑一个计算机系统,其中每个存储器地址有m位,形成M=2<sub>m</sub>个不同的地址.这样一个机器的告诉缓存被组织成一个有S=2<sub>s</sub>个告诉缓存组的数组,每个组包含E个告诉缓存行.每个行是由一个B=2<SUB>b</SUB>字节的数据库组成的,一个有效位表明这个行是否包含有意义的信息,还有t=m-(b+s)个标记为,它们唯一地标志存储在这个高速缓存行中的块.(此处省略一个图).  
 一行的分布: 有效位...标记...高速缓存块  
 一般而言,高速缓存的结构可以用元组(S,E,B,m)来描述.(组数,一组内有多少行,块字节数,地址位数).高速缓存的大小C是所有块的大小的和,标记为和有效位不包括在内.因此,C=SxExB.  
 当一条加载指令只是CPU从主存地址A中读一个字时,它将地址A发送到高速缓存.如果高速缓存政保存着地址A处那个字的副本,它就立即将那个字发回给CPU.高速缓存的结构使得它能通过简单地检查地址位,找到所请求的字,类似于使用极其简单的哈希函数的哈希表.下面介绍如何工作的:  
 参数S和B将m个地址位分了三个字段  
 地址:标记 t...组索引 s...块偏移 b  
 A中s个组索引位是一个到S个组的数组的索引.第一个组是组0,第二个是1,以此类推.组索引位被解释为一个无符号证书,告诉我们这个字必须存储在哪个组中.一旦知道这个字必须存放在哪个组中,A中的t歌标记为就告诉我们这个组的哪一行包含这个字(如果有的话).当且仅当设置了有效位并且该行的标记位与地址A中的标记位相匹配时,组中的这一行才包含这个字.b个块偏移位给出了在B个字节的数据块中的字偏移.  
  
 基本参数  
 S...组数  
 E...每个组的行数  
 B...块大小  
 m.log2(M)...主存物理地址位数  
  
 衍生出来的量  
 M...内存地址的最大数量
 s...组索引位数量  
 b...块偏移位数量  
 t...标记位数量  
 C=BxExS...不包括像有效位和标记位这样开销的高速缓存大小
 
##6.4.2 直接映射高速缓存
 根据每个组的高速缓存行数E，高速缓存被分为不同的类，每个组只有一行(E=1)的高速缓存称为**直接映射高速缓存**.  
 具体分为三个步骤：组选择；行匹配；字抽取。  
 **1.直接映射高速缓存中的组选择**  
 高速缓存从w的地址中间抽取出s个组索引位。这些位被解释成一个对应于一个组号的无符号整数。换句话来说，如果把高速缓存看成是一个关于组的一维数组，那么这些组所因为就是一个到这个数组的索引。  
 **2.直接映射高速缓存中的行匹配**  
 在上一步已经选择了某个组i,接下来要确定是否有字w的一个副本存储在组i包含的一个高速缓存行中。直接映射高速缓存只有一行。当且仅当设置了有效位，而且高速缓存行中的标记与w的地址中的标记相匹配时，这一行中包含w的一个副本。  
 **3.直接映射高速缓存的字选择**  
 一旦命中，就知道w再这个块中某个地方。根据块偏移位来确定第一个字节的偏移，把块看成一个字节数组。而字节偏移是到这个数组的一个索引。  
 **4.直接映射高速缓存中不命中时的行替换**  
 如果不命中时，取出一个新的，来替换当前行，因为此组只有一行。  
 详细信息参照 P429 较重要。把实际的内存地址，按照二进制位形式，赋予不同的意义，如上述参数，从而和缓存进行关联。  
 **6.直接映射高速缓存中的冲突不命中**  
 ```
 float dotprod(float x[8],float y[8])
 {
     float sum = 0.0;
     int i;
     
     for(i = 0; i < 8; i++)
        sum += x[i] * y[i];
     return sum;
 }
 ```
 假设浮点数是4个字节，x被加载到从地址0开始的32字节连续内存，y紧随其后，假设一个块是16字节（可以装4个），高速缓存由两个组组成，高速缓存的整个大小为32字节。假设每个x[i]和y[i]都会映射到相同的高速缓存组。  
 运行时，循环第一次迭代引用x[0]，缓存不明智会导致x[0]~x[3]的块被加载到组0，接下来对y[0]引用，又一次不命中，导致y[0]~y[3]被复制到组0，覆盖掉x的块。下一次迭代中，x[1]又发生了不命中。这样的称为x和y的块之间抖动，即高速缓存反复的加载和驱逐相同的告诉缓存块的组。  
 简单的说就是，程序有良好的空间局部性，而高速缓存中也有足够的空间来存放x[i]和y[i]的块，每次引用还是会导致冲突不明智，因为这些块被映射到相同的组中。  
 修复方法为，再每个数组的结尾放B字节的填充。 不是将x定义位float x[8]，而是定义成 float x[12].这样，x[i]和y[i]就被映射到了不同的组。  
 思想就是，将x[i]和y[i]映射到不同的组中，加载的过程中不会发生覆盖现象，减少不命中情况的出现。  
 PS:**为什么用中间的位来做索引**  
 如果高位用作索引，那么一些连续的内存块就会映射到相同的高速缓存块中。  
###6.4.3组相连高速缓存  
 直接映射高速缓存中冲突不命中造成的问题源于每个组只有一行。组相连高速缓存放松了这个限制。  
 **1.组相连高速缓存中的组选择**  
 同直接映射高速缓存。  
 **2.组相联高速缓存中的行匹配和字选择**  
 行匹配比直接映射中的更复杂，因为它必须检查多个行的标记位和有效位，以确定请求的字是否在集合中。相联存储器时一个(key,value)对的数组，已key为输入，返回与输入的key相匹配的(key,value)对中的value值。  
 **3.组相联高速缓存中不命中时的行替换**  
 发生不命中时，高速缓存必须从内存中取出包含这个字的块。然而再替换时，需要用到替换策略。随机替换最简单，也有最近不常用，最近最少使用策略。  
###6.4.4全相联高速缓存  
 即只有一个组，包含所有高速缓存行。和直接映射有点相反的感觉。  
 **1.全相联高速缓存中的组选择**  
 只有一个组，选个锤子。。所以地址只被划分为t位标记和b位块偏移。没有组索引位。  
 **2.行匹配和字选择**  
 和组相联一样。只是规模大小的问题。全相联高速缓存只适合做小的高速缓存。  
 
###6.4.5有关写的问题  
 高速缓存关于读的操作非常简单，首先在高速缓存中查找所需字w的副本。如果命中就返回w给CPU.不命中，从存储器层次结构中较低层中取出包含w的块，存储到某个高速缓存行中（可能会驱逐某一行），然后返回字W.  
 写的情况要复杂一点，如果要写一个已经缓存了的字w(写命中）。在高速缓存更新了它的w的副本之后，怎么更新w在层次结构中低一层中的副本呢？最简单的方法称为**直写**，就是立即将w的高速缓存块写回到低一层中，虽然简单，但是缺点是每次写都会引起总线流量。  
 另一种方法，称为写回，尽可能地推迟更新，只有当替换算法要驱逐这个更新过的块时，才把它写到紧接着的低一层中，缺点是增加了复杂性。高速缓存必须位每个高速缓存行维护一个额外的修改位，表明这个高速缓存块是否被修改过。  
 另一个问题是如何处理写不命中,一种方法称为写分配，加载相应的第一层中的块到高速缓存中，然后更新这个高速缓存块。写分配师徒利用写的孔间距不行，但是缺点时每次不命中都会导致一个块从低一层传送到高速缓存。  
 另一种方法称为非写分配，避开高速缓存，直接把这个字写到第一层中，直写高速缓存通常时非写分配的，写回高速缓存通常是写分配的。  
 
###6.4.7高速缓存参数的性能影响  
 不命中率：在一个程序执行或程序的一部分执行器件，内存引用不命中的比率。不命中数量/引用数量。  
 命中率：命中的内存引用比率。  
 命中时间：从高速缓存传送一个字到CPU所需的时间，包括组选择，行确认和字选择的时间。  
 不命中处罚：由于不命中所需要的额外的时间。  
  
 优化高速缓存，可以任性一些定型的折中考量。  
 **1.高速缓存大小的影响**  
 较大的高速缓存可能回提高命中率，使用大存储器运行得更快总是要难一些。结果，较大的高速缓存可能会增加命中时间。  
 **2.块大小的影响**  
 较大的块能利用程序中可能存在的空间局部性，帮助提高命中率。不过，对于给定的高速缓存大小，块越大就意味着高速缓存行数越少，回损害时间局部性比空间局部性更好的程序中的命中率.较大的块对不命中出发也有负面影响，块越大，传送时间越长。  
 **3.相联度的影响**  
 这里的问题时是E的选择，E是每个组中高速缓存行数。较高的相联度(E较大）的优点是降低了高速缓存由于冲突不命中出现抖动的可能性。不过，较高的关联度回造成较高的成本。  
 **4.写策略的影响**  
 直写高速缓存比较容易实现，而且能使用独立于高速缓存的写缓冲区用来更新内存。读不命中开销没有这么打，因为它们不会出发内存写。另一方面，写回高速缓存引起的传送比较少，它允许更多的到内存的贷款用于执行DMA的I/O设备。越往层次结构下面走，传送时间增加，减少传送的数量就变得更加重要。下层尽可能使用写回。  
##6.5编写高速缓存友好的代码  
 确保代码高速缓存友好的基本方法。  
 1.让最常见的情况运行的更快  
 程序把大部分时间都花在少量的核心函数上，而这些函数通常把大部分时间花在了少量循环上。把注意力集中在**核心函数里的循环上**，而忽略其他不分。  
 2.尽量减小每个循环年内不的缓存不命中数量。  
 其他条件（例如加载和存储的总次数）相同的情况下，不命中率较低的循环运行得更快。  
 对局部变量的凡夫引用是好的。补偿位1的引用模式是好的。  
 
 
