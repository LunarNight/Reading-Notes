#优化程序性能  
 编写高效程序需要做以下几点：  
 1. 选择适当的算法和数据结构。  
 2. 理解优化编译器的能力和局限性是很重要的。  
  
 程序优化到达第一步是消除不必要的工作，让代码尽可能有效地执行所期望的任务。这包括消除不必要的函数调用,条件测试和内存引用.这些优化不依赖于目标机  器的任何具体属性.现代计算机用复杂的技术来处理机器级程序,并行地执行许多指令,执行顺序还可能不同于它们在程序中出现的顺序.  
 了解了处理器的运作,就可以进行程序优化的第二步,利用处理器提供的指令级并行能力,同时执行多条指令.  
 性能可能依赖于处理器设计的许多细节特性,而对此我们所知甚少,也是为什么要尝试各种技术的变形和组合的另一个原因.  
 研究程序的汇编代码标示是理解编译器以及产生的代码会如何运行的最有效手段之一.可以预测什么操作会并行执行,以及如何使用处理器资源.常常通过确认关键路径来决定执行一个循环所需要的时间(或者说,是一个时间下界).所谓关键路径是在循环的反复执行过程中形成的数据相关链.  
##5.1优化编译器的能力和局限性  
 编译器必须很小心地对程序只是用**安全化**的优化,也就是说对于程序可能遇到的多有可能的情况,在C语言标准提供的保证之下,优化后和为优化的版本有一样的行为.  
```
void twiddle1(long *xp,long *yp)
{
	*xp+=*yp;
	*xp+=*yp;
}
void twiddle2(long *xp,long *yp)
{
	*xp+=2 * *yp;
	
}
```
 在twiddle2中,两个指针指向同一个内存位置的情况称为**内存别名使用**.  
 乍一看,两个过程似乎有相同的行为.都是讲存储在由指针yp指示的位置处的值两次加到指针xp指示的位置处的值.另一方面,twiddle2的效率更高一些.它只要求三次内存引用(读\*xp,读\*yp,写\*xp),而twiddle1需要6次.如果要编译器编译过程twiddle1,我们会认为twiddle2执行的计算能产生更有效的代码.  
 不过,当xp等于yp的情况.
 ```
 twiddle1  执行
 *xp+=*xp;  //翻2倍
 *xp+=*xp;  //再翻两倍    即原值的4倍
 
 twiddle2 
 *xp+= 2* *xp; // 变为3倍
 ```
 在只执行安全化的优化中,如果编译器编译器不能确定两个指针是否指向同一个位置,必须假设什么情况都有可能,这就限制了可优化的策略.  
  
 ```
 long counter = 0;
 long f(){
 	return counter++;
 }
 long func1(){
 	return f()+f()+f()+f();
 }
 long func2(){
 	return 4*f();
 }
 ```
 上述过程中,看似 func1和func2产生的结果相同,但是函数调用的次数不同,f函数改变了全局变量counter.  
 两个函数执行的结果:  
 func1 = 0 + 1 + 2 + 3 =6;  
 func2 = 4\*0 = 0;  
 大多数编译器不会试图判断一个函数是否没有副作用,如果没有,就可能被优化成像func2亿元.  
 相反,编译器会假设最糟糕的情况,并保持所有的函数调用不变.  
 **内联函数**,即函数在编译过程中,把调用此函数的位置,替换为函数体.增加代码的数量,但是运行速度会加快一些.空间换时间.  
##5.2 表示程序性能
 引入度量标准**每元素的周期数(Cycles Per Element,CPE)**作为一种表示程序性能并指导改进代码的方法.  
 处理器活动的顺序是由时钟控制的,时钟提供了某个频率的规律信号,通常用**千兆赫兹(GHz)**,即十亿周期美妙来标示.例如,当表明一个系统有"4Gz"处理器,标示处理器时钟运行频率为每秒4 x 10<sup>9</sup>个周期.每个时钟周期的时间是时钟频率的倒数.用时钟周期来表示度量标准更合适.度量值表示的是执行了多少条指令,而不是时钟运行的多快.  
```
void psum1(float a[],float p[],long n)
{
 	long i;
	p[0] = a[0];
	for(i = 1; i < n; i++)
		p[i] = p[i-1] + a[i];
}

void psum2(float a[],float p[],long n)
{
	long i;
	p[0] = a[0];
	for (i = 1; i < n-1; i+=2){
		float mid_val = p[i-1] + a[i];
		p[i] = mid_val;
		p[i+1] = mid_val + a[i+1];
	}
	if(i < n)
		p[i] = p[i-1] + a[i];
}
 ```
 函数psum1每次迭代计算结果向量的一个元素.第二个函数使用**循环展开**的技术,每次迭代计算两个元素.  
 结果发现,psum1和psum2的运行时间(以时钟周期为单位)分别近似于等式368+9.0n 和 368+6.0n.  
 这两个等式表明对代码设计时和初始化过程,准备循环以及完成过程的开销为368个市中周期加上每个元素6.0或9.0周期的线性因子.  
 对于较大的n的值,运行时间就会主要由线性因子决定.这些项中的系数称为**每元素的周期数(CPE)**的有效值.  
##5.3 程序示例
 ```
 typedef long data_t;
 typedef struct {
 	long len;
	data_t *data;
 }vec_rec,*vec_ptr;
 
 /*Creat vector of specified length*/
 vec_ptr new_vec(long len)
 {
 	/* Allocate header structure */
	vec_ptr result = (vec_ptr) malloc(sizeof(vec_rec));
	data_t *data = NULL;
	if(!result)
		return NULL;
	result->len = len;
	
	if(len >0){
		data = (data_t *)calloc(len,sizeof(data_t));
		if(!data){	
			free((void *) result);
			return NULL; 		/*Could not allocate storage */
		}
	}
	
	result->data = data;
	return result;
 }
 /*Retrieve vector element and store at dest
   Return 0(out of bounds) or 1 (successful)
 */
 int get_vec_element(vec_ptr v, long index, data_t *dest)
 {
 	if(index < 0 || index >= v->len)
		return 0;
	*dest = v->data[index];
	return 1;
 }
 
 long vec_length(vec_ptr v)
 {
 	return v->len;
 }
 ```
##5.4 消除循环的低效率
 ```
 //下面这段代码,可以重编译成对数据执行不同的运算
 
 #define IDENT 0		//#define IDENT 1
 #define OP +			//#define OP *
 
 void combine1(vec_ptr v,data_t *dest)
 {
 	long i;
	
	*dest = IDENT;
	for(i = 0; i < vec_length(v); i++){
		data_t val;
		get_vec_element(v,i,&val);
		*dest = *dest OP val;
	}
 }
 
 void combine2(vec_ptr v,data_t *dest)
 {
 	long i;
	long length = vec_length(v);
	
	*dest = IDENT;
	for(i = 0; i < length; i++){
		data_t val;
		get_vec_element(v,i,&val);
		*dest = *dest OP val;
	}
 }
 ```
 过程combine1 调用函数 vec_length作为for循环的测试条件.  
 过程combine2 在开始时调用函数,并把结果赋值给**局部变量**length.  
 这样的话,减少了函数 vec_length的调用, 函数1,执行完一次循环体,都要调用函数,进行比较.函数2因为把数据保存在一个局部变量当中,可以直接取值比较.  
 假设这个函数是一个for循环来统计长度,那么 combine1的时间复杂度为n<sup>2</sup>,而combine2的时间复杂度为 n.  
 
 ##5.5 减少过程调用
 像上面的例子,过程调用会带来开销,妨碍大多数形式的程序优化.从combine2的代码看出,每次循环迭代都会调用get_vec_element来获取下一个向量元素.这个函数要把向量索引i与循环边界做笔记,很明显会造成低效率.在处理任意的数组访问时,边界检查可能是个很有用的特性,但是对combine2代码的简单分析表明所有的引用都是合法的.  
 作为替代,假设为抽象数据类型增加一个函数get_vec_start.这个函数返回数组的起始地址.  
 ```
 data_t *get_vec_start(vec_ptr v)
 {
 	return v->data;
 }
 
 void combine3(vec_ptr v,data_t *dest)
 {
 	long i;
	long length = vec_length(v);
	data_t *data = get_vec_start(v);
	
	*dest = IDENT;
	for( i = 0; i < length; i++){
		*dest = *dest OP data[i];
	}
 }
 ```
 函数combine3其内循环里没有函数调用.它没有用函数调用来获取每个向量元素,而是直接访问数组.  
 一个纯粹主义者可能会说这种变换严重损害了程序的模块性.原则上来说,向量抽象类型的使用者甚至不应该需要知道向量的内容是作为数组来存储的,而不是作为诸如链表之类的某种其他数据结构来存储的.比较实际的程序员会争论说这种变换是活的高性能结果的必要步骤.  
 然而,根据图表(省略..)来看,性能没有明显的提示.事实上,整数求和的性能还略有下降.显然,内循环中的**其他操作**形成了平静,限制性能超过调用get_vec_element.我们可以兼职合格转换视为一系列步骤中的一步,这些步骤将最终产生显著的性能提升.  
##5.6 消除不必要的内存引用
 combine3的代码将合并运算计算的值累计在指针dest指定的位置.通过检查变异出来的为内存换产生的汇编代码,可以看出这个属性.  
 ```
 Inner loop of combine3. data_t = double, OP = *
 dest in %rbx,data+i in %rdx, data+length in %rax
 .L17
 	vmovsd (%rbx), %xmm0    	Read product from dest
	vmulsd (%rdx), %xmm0, %xmm0	Multiply product by data[i]
	vmovsd %xmm, (%rbx)		Store product at dest
	addq   &8, %rdx			Increment data+i
	cmpq   %rax, %rdx		Compare to data+length
	jne    .L17			If !=,goto loop
 ```
 这段循环代码中,指针dest的地址存放在寄存器rbx中,它还改变了代码,将第i个数据元素的指针保存在寄存器rdx中.注释中显示为data+i,每次迭代,这个指针都加8.循环终止操作通过比较这个指针和保存在寄存器%rax中的数值来判断.我们可以看到每次迭代时,**累计变量(dest)**的数值都要**从内存读出再写入到内存**.这样的读写很费时间.  
 可以按照如下方式消除这种不必要的内存读写.  
 ```
  Inner loop of combine3. data_t = double, OP = *
  acc in %xmm0,data+i in %rdx, data+length in %rax
 .L25
	vmulsd (%rdx), %xmm0, %xmm0	Multiply product by data[i]
	addq   &8, %rdx			Increment data+i
	cmpq   %rax, %rdx		Compare to data+length
	jne    .L25			If !=,goto loop
	
void combine4(vec_ptr v, data_t *dest)
{
	long i;
	long length = vec_length(v);
	data_t *data = get_vec_start(v);
	data_t acc = IDENT;
	
	for( i = 0; i < length; i++){
		acc = acc OP data[i];   //这是重点 操作指针变为操作一个临时变量
	}
	*dest = acc;		  
}
 ```
 把结果累计在临时变量中,将累计值存放在局部变量acc(累积器(accumulator)的简写)中,消除了每次循环迭代中从内存中读出兵将更新值写回的需要.  
 程序性能有了显著的提高.  
 这两个函数看似一样,由于内存别名使用,两个函数可能会有不同的行为.例如,考虑 整数数据,乘法,标志元素为1的情况.  
 ```
 设 v =[2,3,5] 是一个有3个元素组成的向量  
 考虑如下两个函数的调用
 
 combine3(v,get_vec_start(v)+2);   //也就是 combine(v,3)  所有数的积,赋值给 第三个元素
 combine4(v,get_vec_start(v)+2);
 
 执行结果如下:
 函数        初始值      循环前       i = 0       i = 1     i = 2       最后
 combine3    [2,3,5]     [2,3,1]     [2,3,2]     [2,3,6]   [2,3,36]   [2,3,36] 
 combine4    [2,3,5]     [2,3,5]     [2,3,5]     [2,3,5]   [2,3,5]    [2,3,30] 
 
 combine3 操作的是内存,直接变
 combine4 没有对它进行操作,只是在最后循环结束的时候,把 acc的值传了过去.  
 ```
 combine3和combine4之间差别的例子是认为设计的.有人会说combine4的行为更加符合函数描述的意图.不幸的是,编译器不能判断函数会在什么情况下被调用,以及程序员的本意可能是什么.取而代之,在编译combine3时,保守的方法是不断地进行读和写内存,即使这样做效率不太高.  
 **尽量减少在循环中的内存调用,用临时变量来存储数值,最后传递给相应指针,只是一种思想,还要看具体的实现是否适合**  
 
##5.7 理解现代处理器
 在代码级上,看上去似乎是一次执行一条指令,每条指令都包括从寄存器或内存取值,执行一个操作,并把结果存回到一个寄存器或内存位置.  
 在实际的处理器中,是同时对多条指令求值的,这个现象称为**指令级并行**.  
 我们发现两种下界描述了程序的最大性能:  
 1. 当一系列操作必须按照严格顺序执行时,会遇到**延迟界限(latency bound)**,因为在下一条指令开始之前,这条指令必须结束.当代码中的数据相关限制了处理器利用指令级并行的能力时,延迟界限能够限制程序性能.  
 2. **吞吐量界限(throunghput bound)**刻画了处理器功能单元的原始计算能力.这个界限是程序性能的终极限制.  
###5.7.1 整体操作
 基于近期的Intel处理器的结构的处理器,在工业界称为**超标量**,意思是它可以再每个时钟周期执行多个操作,而且是**乱序的**,指令执行的顺序不一定要与它们在机器级程序中的顺序一致.整个设计有两个主要部分:**指令控制单元**和**执行单元**.前者负责从内存中读出指令序列,并根据这些指令序列生成一组针对程序数据的基本操作;而后者执行这些操作.  
  ![image](https://github.com/nightriain/Reading-Notes/blob/master/CSAPP/image/ice.png)   
 ICU从**指令高速缓存(instruction cache)**中读出指令,指令高速缓存是一个特殊的高速存储器,它包含最近访问的指令.通常,ICU会在当前正在执行的指令很早之前取指,这样它才有足够的时间对指令译码,并把操作发送到EU.  
 现代处理器采用了一种称为**分支预测**的技术,处理器会猜测是否会选择分支,同时还预测分支的目标地址.使用**投机执行**的技术
 
 
##总结
 本章主要讲了程序性能优化,从给出的一个程序,经过各种方面的优化,一步步的去进行试探,看看究竟什么才是影响性能的瓶颈,然后发现瓶颈,进行解决,从而提高运行速度.  
 分析时需要查看相关的代码的汇编代码.  
 
 循环中 操作指针变为操作一个局部变量, 不用从内存中加载  
 
