#优化程序性能  
 编写高效程序需要做以下几点：  
 1. 选择适当的算法和数据结构。  
 2. 理解优化编译器的能力和局限性是很重要的。  
  
 程序优化到达第一步是消除不必要的工作，让代码尽可能有效地执行所期望的任务。这包括消除不必要的函数调用,条件测试和内存引用.这些优化不依赖于目标机  器的任何具体属性.现代计算机用复杂的技术来处理机器级程序,并行地执行许多指令,执行顺序还可能不同于它们在程序中出现的顺序.  
 了解了处理器的运作,就可以进行程序优化的第二步,利用处理器提供的指令级并行能力,同时执行多条指令.  
 性能可能依赖于处理器设计的许多细节特性,而对此我们所知甚少,也是为什么要尝试各种技术的变形和组合的另一个原因.  
 研究程序的汇编代码标示是理解编译器以及产生的代码会如何运行的最有效手段之一.可以预测什么操作会并行执行,以及如何使用处理器资源.常常通过确认关键路径来决定执行一个循环所需要的时间(或者说,是一个时间下界).所谓关键路径是在循环的反复执行过程中形成的数据相关链.  
##5.1优化编译器的能力和局限性  
 编译器必须很小心地对程序只是用**安全化**的优化,也就是说对于程序可能遇到的多有可能的情况,在C语言标准提供的保证之下,优化后和为优化的版本有一样的行为.  
```
void twiddle1(long *xp,long *yp)
{
	*xp+=*yp;
	*xp+=*yp;
}
void twiddle2(long *xp,long *yp)
{
	*xp+=2 * *yp;
	
}
```
 在twiddle2中,两个指针指向同一个内存位置的情况称为**内存别名使用**.  
 乍一看,两个过程似乎有相同的行为.都是讲存储在由指针yp指示的位置处的值两次加到指针xp指示的位置处的值.另一方面,twiddle2的效率更高一些.它只要求三次内存引用(读\*xp,读\*yp,写\*xp),而twiddle1需要6次.如果要编译器编译过程twiddle1,我们会认为twiddle2执行的计算能产生更有效的代码.  
 不过,当xp等于yp的情况.
 ```
 twiddle1  执行
 *xp+=*xp;  //翻2倍
 *xp+=*xp;  //再翻两倍    即原值的4倍
 
 twiddle2 
 *xp+= 2* *xp; // 变为3倍
 ```
 在只执行安全化的优化中,如果编译器编译器不能确定两个指针是否指向同一个位置,必须假设什么情况都有可能,这就限制了可优化的策略.  
  
 ```
 long counter = 0;
 long f(){
 	return counter++;
 }
 long func1(){
 	return f()+f()+f()+f();
 }
 long func2(){
 	return 4*f();
 }
 ```
 上述过程中,看似 func1和func2产生的结果相同,但是函数调用的次数不同,f函数改变了全局变量counter.  
 两个函数执行的结果:  
 func1 = 0 + 1 + 2 + 3 =6;  
 func2 = 4\*0 = 0;  
 大多数编译器不会试图判断一个函数是否没有副作用,如果没有,就可能被优化成像func2亿元.  
 相反,编译器会假设最糟糕的情况,并保持所有的函数调用不变.  
 **内联函数**,即函数在编译过程中,把调用此函数的位置,替换为函数体.增加代码的数量,但是运行速度会加快一些.空间换时间.  
##5.2 表示程序性能
 引入度量标准**每元素的周期数(Cycles Per Element,CPE)**作为一种表示程序性能并指导改进代码的方法.  
 处理器活动的顺序是由时钟控制的,时钟提供了某个频率的规律信号,通常用**千兆赫兹(GHz)**,即十亿周期美妙来标示.例如,当表明一个系统有"4Gz"处理器,标示处理器时钟运行频率为每秒4 x 10<sup>9</sup>个周期.每个时钟周期的时间是时钟频率的倒数.用时钟周期来表示度量标准更合适.度量值表示的是执行了多少条指令,而不是时钟运行的多快.  
```
void psum1(float a[],float p[],long n)
{
 	long i;
	p[0] = a[0];
	for(i = 1; i < n; i++)
		p[i] = p[i-1] + a[i];
}

void psum2(float a[],float p[],long n)
{
	long i;
	p[0] = a[0];
	for (i = 1; i < n-1; i+=2){
		float mid_val = p[i-1] + a[i];
		p[i] = mid_val;
		p[i+1] = mid_val + a[i+1];
	}
	if(i < n)
		p[i] = p[i-1] + a[i];
}
 ```
 函数psum1每次迭代计算结果向量的一个元素.第二个函数使用**循环展开**的技术,每次迭代计算两个元素.  
 结果发现,psum1和psum2的运行时间(以时钟周期为单位)分别近似于等式368+9.0n 和 368+6.0n.  
 这两个等式表明对代码设计时和初始化过程,准备循环以及完成过程的开销为368个市中周期加上每个元素6.0或9.0周期的线性因子.  
 对于较大的n的值,运行时间就会主要由线性因子决定.这些项中的系数称为**每元素的周期数(CPE)**的有效值.  
##5.3 程序示例
 ```
 typedef long data_t;
 typedef struct {
 	long len;
	data_t *data;
 }vec_rec,*vec_ptr;
 
 /*Creat vector of specified length*/
 vec_ptr new_vec(long len)
 {
 	/* Allocate header structure */
	vec_ptr result = (vec_ptr) malloc(sizeof(vec_rec));
	data_t *data = NULL;
	if(!result)
		return NULL;
	result->len = len;
	
	if(len >0){
		data = (data_t *)calloc(len,sizeof(data_t));
		if(!data){	
			free((void *) result);
			return NULL; 		/*Could not allocate storage */
		}
	}
	
	result->data = data;
	return result;
 }
 /*Retrieve vector element and store at dest
   Return 0(out of bounds) or 1 (successful)
 */
 int get_vec_element(vec_ptr v, long index, data_t *dest)
 {
 	if(index < 0 || index >= v->len)
		return 0;
	*dest = v->data[index];
	return 1;
 }
 
 long vec_length(vec_ptr v)
 {
 	return v->len;
 }
 ```
##5.4 消除循环的低效率
 ```
 //下面这段代码,可以重编译成对数据执行不同的运算
 
 #define IDENT 0		//#define IDENT 1
 #define OP +			//#define OP *
 
 void combine1(vec_ptr v,data_t *dest)
 {
 	long i;
	
	*dest = IDENT;
	for(i = 0; i < vec_length(v); i++){
		data_t val;
		get_vec_element(v,i,&val);
		*dest = *dest OP val;
	}
 }
 
 void combine2(vec_ptr v,data_t *dest)
 {
 	long i;
	long length = vec_length(v);
	
	*dest = IDENT;
	for(i = 0; i < length; i++){
		data_t val;
		get_vec_element(v,i,&val);
		*dest = *dest OP val;
	}
 }
 ```
 过程combine1 调用函数 vec_length作为for循环的测试条件.  
 过程combine2 在开始时调用函数,并把结果赋值给**局部变量**length.  
 这样的话,减少了函数 vec_length的调用, 函数1,执行完一次循环体,都要调用函数,进行比较.函数2因为把数据保存在一个局部变量当中,可以直接取值比较.  
 假设这个函数是一个for循环来统计长度,那么 combine1的时间复杂度为n<sup>2</sup>,而combine2的时间复杂度为 n.  
 
 ##5.5 减少过程调用
 像上面的例子,过程调用会带来开销,妨碍大多数形式的程序优化.从combine2的代码看出,每次循环迭代都会调用get_vec_element来获取下一个向量元素.这个函数要把向量索引i与循环边界做笔记,很明显会造成低效率.在处理任意的数组访问时,边界检查可能是个很有用的特性,但是对combine2代码的简单分析表明所有的引用都是合法的.  
 作为替代,假设为抽象数据类型增加一个函数get_vec_start.这个函数返回数组的起始地址.  
 ```
 data_t *get_vec_start(vec_ptr v)
 {
 	return v->data;
 }
 
 void combine3(vec_ptr v,data_t *dest)
 {
 	long i;
	long length = vec_length(v);
	data_t *data = get_vec_start(v);
	
	*dest = IDENT;
	for( i = 0; i < length; i++){
		*dest = *dest OP data[i];
	}
 }
 ```
 函数combine3其内循环里没有函数调用.它没有用函数调用来获取每个向量元素,而是直接访问数组.  
 一个纯粹主义者可能会说这种变换严重损害了程序的模块性.原则上来说,向量抽象类型的使用者甚至不应该需要知道向量的内容是作为数组来存储的,而不是作为诸如链表之类的某种其他数据结构来存储的.比较实际的程序员会争论说这种变换是活的高性能结果的必要步骤.  
 然而,根据图表(省略..)来看,性能没有明显的提示.事实上,整数求和的性能还略有下降.显然,内循环中的**其他操作**形成了平静,限制性能超过调用get_vec_element.我们可以兼职合格转换视为一系列步骤中的一步,这些步骤将最终产生显著的性能提升.  
##5.6 消除不必要的内存引用
 combine3的代码将合并运算计算的值累计在指针dest指定的位置.通过检查变异出来的为内存换产生的汇编代码,可以看出这个属性.  
 ```
 Inner loop of combine3. data_t = double, OP = *
 dest in %rbx,data+i in %rdx, data+length in %rax
 .L17
 	vmovsd (%rbx), %xmm0    	Read product from dest
	vmulsd (%rdx), %xmm0, %xmm0	Multiply product by data[i]
	vmovsd %xmm, (%rbx)		Store product at dest
	addq   &8, %rdx			Increment data+i
	cmpq   %rax, %rdx		Compare to data+length
	jne    .L17			If !=,goto loop
 ```
 这段循环代码中,指针dest的地址存放在寄存器rbx中,它还改变了代码,将第i个数据元素的指针保存在寄存器rdx中.注释中显示为data+i,每次迭代,这个指针都加8.循环终止操作通过比较这个指针和保存在寄存器%rax中的数值来判断.我们可以看到每次迭代时,**累计变量(dest)**的数值都要**从内存读出再写入到内存**.这样的读写很费时间.  
 可以按照如下方式消除这种不必要的内存读写.  
 ```
  Inner loop of combine3. data_t = double, OP = *
  acc in %xmm0,data+i in %rdx, data+length in %rax
 .L25
	vmulsd (%rdx), %xmm0, %xmm0	Multiply product by data[i]
	addq   &8, %rdx			Increment data+i
	cmpq   %rax, %rdx		Compare to data+length
	jne    .L25			If !=,goto loop
	
void combine4(vec_ptr v, data_t *dest)
{
	long i;
	long length = vec_length(v);
	data_t *data = get_vec_start(v);
	data_t acc = IDENT;
	
	for( i = 0; i < length; i++){
		acc = acc OP data[i];   //这是重点 操作指针变为操作一个临时变量
	}
	*dest = acc;		  
}
 ```
 把结果累计在临时变量中,将累计值存放在局部变量acc(累积器(accumulator)的简写)中,消除了每次循环迭代中从内存中读出兵将更新值写回的需要.  
 程序性能有了显著的提高.  
 这两个函数看似一样,由于内存别名使用,两个函数可能会有不同的行为.例如,考虑 整数数据,乘法,标志元素为1的情况.  
 ```
 设 v =[2,3,5] 是一个有3个元素组成的向量  
 考虑如下两个函数的调用
 
 combine3(v,get_vec_start(v)+2);   //也就是 combine(v,3)  所有数的积,赋值给 第三个元素
 combine4(v,get_vec_start(v)+2);
 
 执行结果如下:
 函数        初始值      循环前       i = 0       i = 1     i = 2       最后
 combine3    [2,3,5]     [2,3,1]     [2,3,2]     [2,3,6]   [2,3,36]   [2,3,36] 
 combine4    [2,3,5]     [2,3,5]     [2,3,5]     [2,3,5]   [2,3,5]    [2,3,30] 
 
 combine3 操作的是内存,直接变
 combine4 没有对它进行操作,只是在最后循环结束的时候,把 acc的值传了过去.  
 ```
 combine3和combine4之间差别的例子是认为设计的.有人会说combine4的行为更加符合函数描述的意图.不幸的是,编译器不能判断函数会在什么情况下被调用,以及程序员的本意可能是什么.取而代之,在编译combine3时,保守的方法是不断地进行读和写内存,即使这样做效率不太高.  
 **尽量减少在循环中的内存调用,用临时变量来存储数值,最后传递给相应指针,只是一种思想,还要看具体的实现是否适合**  
 
##5.7 理解现代处理器
 在代码级上,看上去似乎是一次执行一条指令,每条指令都包括从寄存器或内存取值,执行一个操作,并把结果存回到一个寄存器或内存位置.  
 在实际的处理器中,是同时对多条指令求值的,这个现象称为**指令级并行**.  
 我们发现两种下界描述了程序的最大性能:  
 1. 当一系列操作必须按照严格顺序执行时,会遇到**延迟界限(latency bound)**,因为在下一条指令开始之前,这条指令必须结束.当代码中的数据相关限制了处理器利用指令级并行的能力时,延迟界限能够限制程序性能.  
 2. **吞吐量界限(throunghput bound)**刻画了处理器功能单元的原始计算能力.这个界限是程序性能的终极限制.  
###5.7.1 整体操作
 基于近期的Intel处理器的结构的处理器,在工业界称为**超标量**,意思是它可以再每个时钟周期执行多个操作,而且是**乱序的**,指令执行的顺序不一定要与它们在机器级程序中的顺序一致.整个设计有两个主要部分:**指令控制单元**和**执行单元**.前者负责从内存中读出指令序列,并根据这些指令序列生成一组针对程序数据的基本操作;而后者执行这些操作.  
  ![image](https://github.com/nightriain/Reading-Notes/blob/master/CSAPP/image/ice.png)   
 ICU从**指令高速缓存(instruction cache)**中读出指令,指令高速缓存是一个特殊的高速存储器,它包含最近访问的指令.通常,ICU会在当前正在执行的指令很早之前取指,这样它才有足够的时间对指令译码,并把操作发送到EU.  
 现代处理器采用了一种称为**分支预测**的技术,处理器会猜测是否会选择分支,同时还预测分支的目标地址.使用**投机执行**的技术,处理器会开始取出位于它预测的分支会调到的地方的指令,并对指令译码,甚至在它确定分支预测是否正确之前就开始执行这些操作.如果过后确定分支预测错误,会将状态重新设置到分支点的状态,并开始取出和执行另一个方向上的指令.标记为**取指控制**块包括分支预测,以完成确定取哪些指令的任务.  
 **指令译码**逻辑接受实际的程序指令,并将它们转换成一组基本操作(微操作).  
 EU接收来自取指单元的操作.通常每个始终周期会接收多个操作.这些操作会被分派到一组**功能单元**中,它们会执行实际的操作.这些功能单元专门用来处理不同类型的操作.  
 读写内存是由加载和存储单元实现的.加载单元处理从内存读数据到处理器的操作,有一个加法器来完成地址计算.  
 存储单元处理从处理器写数据到内存的操作,它也有一个加法器来完成地址计算.  
 如图所示,加载和存储单元通过**数据高速缓存**来访问内存.数据高速缓存是一个高速存储器,存放着最近访问的数据值.  
 使用投机执行技术对操作求值,但是最终结果不会存放在程序寄存器或数据内存中,直到处理器能确定应该实际执行这些指令.分支操作被送到EU,不是确定分支该往哪里去,而是确定分支预测是否正确.如果预测错误,EU会丢弃分支点之后计算出来的结果.它还会发信号给分支单元,说预测是错误的,并指出正确的分支目的.在这种情况下,分支单元开始在新的位置取指.这样的**预测错误**会导致很大的性能开销.在可以取出新指令,译码和发送到执行单元之前,要花费一点时间.  
 在ICU中,**退役单元**记录正在进行的处理,并确保它遵守机器级程序的顺序语义.图中展示了一个**寄存器文件**,包含整数,浮点数和最近的SSE和AVX寄存器,是退役单元的一部分,因为退役单元控制这些寄存器的更新.指令译码时,关于指令的信息被放置在一个先进先出的队列中.这个信息会一致保存在队列中,直到发生以下两个结果中的一个:  
 1. 一旦一条指令的操作完成,所有引起这条指令的分支点页都被确定为预测正确,那么这条指令可以**退役**.所有对程序寄存器的更新都可以被实际执行了.  
 2. 如果引起该指令的某个分支点预测错误,这条指令会被情况,丢弃所有计算出来的结果.这样,预测错误就不会改变程序的状态了.  
  
 **任何对程序寄存器的更新都会只在指令退役时才会发生,只有处理器能够确信的熬制这条指令的所有分支都预测正确了,才会这样做**.  
 控制操作数在执行单元件传送的最常见的机制称为**寄存器重命名**.当一条更新寄存器r的指令译码时,产生标记t,得到一个指向该操作结果的唯一的标识符.条目(r,t)被加入到一张表中,该表维护着每个程序寄存器r与会更新该寄存器的操作的标记t之前的关联.当随后以寄存器r作为操作数的指令译码时,发送到执行单元的操作会包含t作为操作数源的值.当某个执行单元完成第一个操作时,会生成一个结果(v,t),指明标记为t的操作产生值v.所有等待t作为源的操作都能使用v作为源值,这就是一种形式的数据转发.  
 通过这种机制,值可以从一个操作直接转发到另一个操作,而不是写到寄存器文件再读出来,使得第二个操作能够在第一个操作完成后尽快开始.重命名表只包含关于有未进行写操作的寄存器条目.当一条被译码的指令需要寄存器r,而又没有标记与这个寄存器相关联,可以直接从寄存器文件中获取这个操作数.有了寄存器重命名,即使只有在处理器确定了分支结果之后才能更新寄存器,也可以预测执行操作的整个序列.  
##5.7.2 功能单元的性能
 每个运算都是由以下这些数值来刻画的:  
 1. 延迟(latency),它表示完成运算所需要的总时间  
 2. 发射时间(issue time),它表示两个连接的同类型的运算之间需要的最小始终周期数  
 3. 容量(capacity),它表示能够执行该运算的功能单元的数量.  
 
 
 
 
 
##总结
 本章主要讲了程序性能优化,从给出的一个程序,经过各种方面的优化,一步步的去进行试探,看看究竟什么才是影响性能的瓶颈,然后发现瓶颈,进行解决,从而提高运行速度.  
 分析时需要查看相关的代码的汇编代码.  
 
 循环中 操作指针变为操作一个局部变量, 不用从内存中加载  
 
